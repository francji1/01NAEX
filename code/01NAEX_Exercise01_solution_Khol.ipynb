{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01NAEX/blob/main/code/01NAEX_Exercise01_solution_Khol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01NAEX - Exercise 01\n",
        "Data and exercises come from D.C. Montgomery: Design and Analysis of Experiment\n"
      ],
      "metadata": {
        "id": "IJZpZoupsfsX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEGyKc3C8teG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26cEQ8Nt8teK"
      },
      "outputs": [],
      "source": [
        "!pip install rpy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCDVk5ts8teL"
      },
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-tQykDJeaY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, t, f, shapiro\n"
      ],
      "metadata": {
        "id": "AzDtqykGeacb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example from the Lecture"
      ],
      "metadata": {
        "id": "pZMT7l0CRtyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data arrays\n",
        "y1 = np.array([16.85,16.40,17.21,16.35,16.52,17.04,16.96,17.15,16.59,16.57])  # Modified Mortar\n",
        "y2 = np.array([16.62,16.75,17.37,17.12,16.98,16.87,17.34,17.02,17.08,17.27])  # Unmodified Mortar\n",
        "\n",
        "# Sample variances\n",
        "s1_squared = np.var(y1, ddof=1)\n",
        "s2_squared = np.var(y2, ddof=1)\n",
        "\n",
        "# Degrees of freedom\n",
        "dfn = len(y1) - 1  # Degrees of freedom numerator\n",
        "dfd = len(y2) - 1  # Degrees of freedom denominator\n",
        "\n",
        "# F-test statistic\n",
        "F = s1_squared / s2_squared\n",
        "\n",
        "# Two-tailed p-value\n",
        "p_value = 2 * min(f.cdf(F, dfn, dfd), 1 - f.cdf(F, dfn, dfd))\n",
        "\n",
        "print('F-statistic:', F)\n",
        "print('Degrees of freedom:', dfn, 'and', dfd)\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "dDJ8QDnXRtD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Independent two-sample t-test (equal variances)\n",
        "t_statistic, p_value = stats.ttest_ind(y1, y2, equal_var=True)\n",
        "\n",
        "print(f't-statistic: {t_statistic}')\n",
        "print(f'p-value: {p_value}')"
      ],
      "metadata": {
        "id": "Ll7-f7eZRtL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Welch's t-test (unequal variances)\n",
        "t_stat, p_value = stats.ttest_ind(y1, y2, equal_var=False)\n",
        "\n",
        "print('Welch\\'s t-statistic:', t_stat)\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "qi3XwWZeSrWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Two-sample t-test assuming equal variances (var.equal = TRUE in R)\n",
        "t_stat_equal_var, p_value_equal_var = stats.ttest_ind(y1, y2, equal_var=True)\n",
        "\n",
        "# Calculate confidence interval for equal variance\n",
        "n1, n2 = len(y1), len(y2)\n",
        "mean_diff = np.mean(y1) - np.mean(y2)\n",
        "pooled_std = np.sqrt(((n1 - 1) * np.var(y1, ddof=1) + (n2 - 1) * np.var(y2, ddof=1)) / (n1 + n2 - 2))\n",
        "se_pooled = pooled_std * np.sqrt(1/n1 + 1/n2)\n",
        "conf_interval_equal_var = stats.t.interval(0.95, df=n1 + n2 - 2, loc=mean_diff, scale=se_pooled)\n",
        "\n",
        "# 2. Welch's t-test (var.equal = FALSE in R)\n",
        "t_stat_unequal_var, p_value_unequal_var = stats.ttest_ind(y1, y2, equal_var=False)\n",
        "df_unequal_var = ((np.var(y1, ddof=1)/n1 + np.var(y2, ddof=1)/n2)**2) / \\\n",
        "                 ((np.var(y1, ddof=1)/n1)**2/(n1-1) + (np.var(y2, ddof=1)/n2)**2/(n2-1))\n",
        "\n",
        "# Calculate confidence interval for unequal variance\n",
        "se_unequal = np.sqrt(np.var(y1, ddof=1)/n1 + np.var(y2, ddof=1)/n2)\n",
        "conf_interval_unequal_var = stats.t.interval(0.95, df=df_unequal_var, loc=mean_diff, scale=se_unequal)\n",
        "\n",
        "# Results for t-test assuming equal variances\n",
        "print(\"Two-Sample T-Test Assuming Equal Variances\")\n",
        "print(f\"t-statistic: {t_stat_equal_var}\")\n",
        "print(f\"p-value: {p_value_equal_var}\")\n",
        "print(f\"95% confidence interval: {conf_interval_equal_var}\")\n",
        "print(f\"Mean of y1: {np.mean(y1)}, Mean of y2: {np.mean(y2)}\")\n",
        "print()\n",
        "\n",
        "# Results for Welch's t-test (unequal variances)\n",
        "print(\"Welch's Two-Sample T-Test (Assuming Unequal Variances)\")\n",
        "print(f\"t-statistic: {t_stat_unequal_var}\")\n",
        "print(f\"p-value: {p_value_unequal_var}\")\n",
        "print(f\"Degrees of freedom: {df_unequal_var}\")\n",
        "print(f\"95% confidence interval: {conf_interval_unequal_var}\")\n",
        "print(f\"Mean of y1: {np.mean(y1)}, Mean of y2: {np.mean(y2)}\")\n"
      ],
      "metadata": {
        "id": "-uzGYiAwTzDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Kernel Density Plot\n",
        "sns.kdeplot(y1, fill=True, label='Modified Mortar')\n",
        "sns.kdeplot(y2, fill=True, label='Unmodified Mortar')\n",
        "plt.title('Kernel Density Estimation of Mortar Data')\n",
        "plt.xlabel('Tension Bond Strength')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9s-P_osZUzSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QQ-Plot for y1\n",
        "plt.figure()\n",
        "stats.probplot(y1, dist=\"norm\", plot=plt)\n",
        "plt.title('Normal QQ-Plot for Modified Mortar')\n",
        "plt.show()\n",
        "\n",
        "# QQ-Plot for y2\n",
        "plt.figure()\n",
        "stats.probplot(y2, dist=\"norm\", plot=plt)\n",
        "plt.title('Normal QQ-Plot for Unmodified Mortar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FnlUCXkxW7qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapiro-Wilk test for y1\n",
        "statistic_y1, p_value_y1 = shapiro(y1)\n",
        "print(f'Shapiro-Wilk Test for y1: Statistic={statistic_y1}, p-value={p_value_y1}')\n",
        "\n",
        "# Shapiro-Wilk test for y2\n",
        "statistic_y2, p_value_y2 = shapiro(y2)\n",
        "print(f'Shapiro-Wilk Test for y2: Statistic={statistic_y2}, p-value={p_value_y2}')"
      ],
      "metadata": {
        "id": "SJe3JXT4W7tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# Parameters\n",
        "effect_size = (np.mean(y1) - np.mean(y2)) / np.sqrt((s1_squared + s2_squared) / 2)\n",
        "alpha = 0.05\n",
        "power = 0.95\n",
        "\n",
        "# Create an instance of the power analysis class\n",
        "analysis = TTestIndPower()\n",
        "\n",
        "# Calculate required sample size\n",
        "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')\n",
        "print(f'Required sample size per group: {np.ceil(sample_size)}')\n",
        "\n",
        "# Calculate power of the test with n=10\n",
        "actual_power = analysis.power(effect_size=effect_size, nobs1=10, alpha=alpha, alternative='two-sided')\n",
        "print(f'Power of the test with n=10 per group: {actual_power}')"
      ],
      "metadata": {
        "id": "pjc3LPqdXVrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# Parameters\n",
        "alpha = 0.05\n",
        "power = 0.80\n",
        "sd = 0.284  # Standard deviation\n",
        "effect_sizes = np.array([0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6])\n",
        "\n",
        "# Calculate sample sizes\n",
        "analysis = TTestIndPower()\n",
        "sample_sizes = []\n",
        "for delta in effect_sizes:\n",
        "    effect_size = delta / sd\n",
        "    n = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')\n",
        "    sample_sizes.append(n)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(effect_sizes, sample_sizes, marker='o')\n",
        "plt.xlabel('Effect Size')\n",
        "plt.ylabel('Sample Size per Group')\n",
        "plt.title('Sample Size vs. Effect Size')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "owtb-8JNYMhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assigment:\n",
        "\n",
        "* Run and familiarize with Python.\n",
        "* Solve problems 2.20, 2.26, 2.30 from following slides.\n",
        "  (originally from Montgomery - Design and Analysis of Experiments).\n"
      ],
      "metadata": {
        "id": "7SzDDewJ0Gps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises 2.20\n",
        "\n",
        "The shelf life of a carbonated beverage is of interest. Ten bottles are randomly\n",
        "selected and tested, and the following results are obtained:\n",
        "\n",
        "| Days ||\n",
        "|--------------------------------------------||\n",
        "| 108      |  138  |\n",
        "| 124      |  163  |\n",
        "| 124      |  159  |\n",
        "| 106      |  134  |\n",
        "| 115      |  139  |\n",
        "\n",
        "* We would like to demonstrate that the mean shelf life exceeds 120 days.\n",
        "Set up appropriate hypotheses for investigating this claim.\n",
        "* Test these hypotheses using significant level $\\alpha = 0.01$. Find the P-value\n",
        "for the test. What are your conclusions?\n",
        "* Construct a 99 percent confidence interval on the mean shelf life."
      ],
      "metadata": {
        "id": "zvHL1CwW0VKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the URL\n",
        "url_20 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Ex02_20.csv\"\n",
        "df20 = pd.read_csv(url_20, sep=\";\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df20.head()\n",
        "\n",
        "# Calculate sample mean and standard deviation\n",
        "sample_mean = np.mean(df20)\n",
        "sample_std = np.std(df20, ddof=1)\n",
        "n = len(df20)\n",
        "\n",
        "# Hypothesized mean\n",
        "mu_0 = 120\n",
        "\n",
        "# t-test for one sample\n",
        "t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))\n",
        "df = n - 1  # degrees of freedom\n",
        "\n",
        "# p-value for the one-tailed test\n",
        "p_value = 1 - t.cdf(t_statistic, df)\n",
        "\n",
        "# Confidence Interval: 99%\n",
        "confidence_level = 0.99\n",
        "t_critical = t.ppf((1 + confidence_level) / 2, df)\n",
        "margin_error = t_critical * (sample_std / np.sqrt(n))\n",
        "ci_lower = sample_mean - margin_error\n",
        "ci_upper = sample_mean + margin_error\n",
        "\n",
        "(sample_mean, sample_std, t_statistic, p_value, (ci_lower, ci_upper))\n"
      ],
      "metadata": {
        "id": "tQr4UVuXtrC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample Mean: {sample_mean}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std}\")\n",
        "print(f\"t-Statistic: {t_statistic}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "print(f\"Confidence Interval: ({ci_lower}, {ci_upper})\")"
      ],
      "metadata": {
        "id": "MzIG3zv7Qu5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOLUTION:"
      ],
      "metadata": {
        "id": "FGZPi3stCt3u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a8QA0oPYtxe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Exercise 2.26\n",
        "\n",
        "The following are the burning times (in minutes) of chemical flares of two different formulations. The design engineers are interested in both the mean and\n",
        "variance of the burning times.\n",
        "\n",
        "|Type1|| Type2 ||\n",
        "|--------------------------------||||\n",
        "| 65 | 82 | 64 | 56 |\n",
        "| 81 | 67 | 71 | 69 |\n",
        "| 57 | 59 | 83 | 74 |\n",
        "| 66 | 75 | 59 | 82 |\n",
        "| 82 | 70 | 65 | 79 |\n",
        "\n",
        "\n",
        "1. Test the hypothesis that the two variances are equal. Use $\\alpha = 0.05$.\n",
        "2. Using the results of part 1), test the hypothesis that the mean burning\n",
        "times are equal. Use $\\alpha = 0.05$. What is the P-value for this test?\n",
        "3. Discuss the role of the normality assumption in this problem. Check the\n",
        "assumption of normality for both types of flares\n",
        "4. If the mean burning times of the two flares differ by as much as 2 minute, find the power of the test. What sample size would be required to detect an actual difference in mean burning time of 1 minute with a power of at least 0.9?"
      ],
      "metadata": {
        "id": "Ylfv4-d_3SEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the URL\n",
        "url_26 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Ex02_26.csv\"\n",
        "df26 = pd.read_csv(url_26, sep=\";\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df26.head()"
      ],
      "metadata": {
        "id": "YtM7AlkJ0UF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOLUTION:"
      ],
      "metadata": {
        "id": "6Lyi5h_xCq-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Type1 Data:\", df26.Type1)\n",
        "print(\"Type2 Data:\", df26.Type2)\n",
        "print(\"Variance of Type1:\", np.var(df26.Type1, ddof=1))\n",
        "print(\"Variance of Type2:\", np.var(df26.Type2, ddof=1))\n",
        "print(\"Mean of Type1:\", np.mean(df26.Type1))\n",
        "print(\"Mean of Type2:\", np.mean(df26.Type2))\n",
        "print(\"Number of observations in Type1:\", len(df26.Type1))\n",
        "print(\"Number of observations in Type2:\", len(df26.Type2))"
      ],
      "metadata": {
        "id": "_CmrTrjuuBMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene, ttest_ind, shapiro, norm, bartlett\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "type1 = df26['Type1'].dropna().values  # Assuming 'Type1' is the column name\n",
        "type2 = df26['Type2'].dropna().values  # Assuming 'Type2' is the column name\n",
        "\n",
        "# 1. Test for equality of variances\n",
        "alpha = 0.05\n",
        "stat, p_value = bartlett(type1, type2)\n",
        "print(f'Bartlett’s test for equal variances: Statistic = {stat}, p-value = {p_value}')\n"
      ],
      "metadata": {
        "id": "OS20BC8Ct4Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample variances\n",
        "type1_squared = np.var(type1, ddof=1)\n",
        "type2_squared = np.var(type2, ddof=1)\n",
        "print(f'type1_squared: {type1_squared}')\n",
        "print(f'type2_squared: {type2_squared}')\n",
        "\n",
        "# Degrees of freedom\n",
        "dfn = len(type1) - 1  # Degrees of freedom numerator\n",
        "dfd = len(type2) - 1  # Degrees of freedom denominator\n",
        "\n",
        "# F-test statistic\n",
        "F = type1_squared / type2_squared\n",
        "print(f'F-statistic: {F}')\n",
        "\n",
        "# Two-tailed p-value\n",
        "p_value = 2 * min(f.cdf(F, dfn, dfd), 1 - f.cdf(F, dfn, dfd))\n",
        "print(f'p-value: {p_value}')"
      ],
      "metadata": {
        "id": "yyrKGUHh8BCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Test for equality of means\n",
        "if p_value > alpha:\n",
        "    # Variances are equal\n",
        "    t_stat, p_mean = ttest_ind(type1, type2, equal_var=True)\n",
        "else:\n",
        "    # Variances are not equal\n",
        "    t_stat, p_mean = ttest_ind(type1, type2, equal_var=False)\n",
        "\n",
        "print(f'T-test for equal means: t-statistic = {t_stat}, p-value = {p_mean}')\n"
      ],
      "metadata": {
        "id": "lLzPC-8Oz31l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Check for normality in both distributions\n",
        "stat1, p_norm1 = shapiro(type1)\n",
        "stat2, p_norm2 = shapiro(type2)\n",
        "print(f'Normality test for Type1: Statistic = {stat1}, p-value = {p_norm1}')\n",
        "print(f'Normality test for Type2: Statistic = {stat2}, p-value = {p_norm2}')\n"
      ],
      "metadata": {
        "id": "2Dt28CR7z4rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting QQ plots for both Type1 and Type2\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# QQ plot for Type1\n",
        "plt.subplot(1, 2, 1)\n",
        "stats.probplot(type1, dist=\"norm\", plot=plt)\n",
        "plt.title('QQ Plot of Type1')\n",
        "\n",
        "# QQ plot for Type2\n",
        "plt.subplot(1, 2, 2)\n",
        "stats.probplot(type2, dist=\"norm\", plot=plt)\n",
        "plt.title('QQ Plot of Type2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tCIWm_j-_hhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calculate power of the test with n=10\n",
        "\n",
        "print(f'actual mean difference {np.mean(type1) - np.mean(type2)}')\n",
        "print(f'actual S {np.sqrt((type1_squared + type2_squared) / 2)}')\n",
        "\n",
        "S_p = np.sqrt((type1_squared + type2_squared) / 2)\n",
        "mean_difference = 2\n",
        "\n",
        "effect_size = (mean_difference/ S_p)\n",
        "print(f'effect_size: {effect_size}')\n",
        "\n",
        "alpha = 0.05\n",
        "power = 0.95\n",
        "\n",
        "actual_power = analysis.power(effect_size=effect_size, nobs1=10, alpha=alpha, alternative='two-sided')\n",
        "print(f'Power of the test with n=10 per group: {actual_power}')"
      ],
      "metadata": {
        "id": "D1KDMLm0AC06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Power analysis to determine sample size\n",
        "effect_size = 2 / np.sqrt((np.var(type1, ddof=1) + np.var(type2, ddof=1)) / 2)\n",
        "power_analysis = TTestIndPower()\n",
        "sample_size = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=0.9, alternative='two-sided')\n",
        "print(f'Required sample size to detect a 2 minute difference with 90% power: {sample_size:.2f}')\n"
      ],
      "metadata": {
        "id": "oOtoVYp2z5UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeating power analysis for a 1 minute difference\n",
        "effect_size = 1 / S_p\n",
        "sample_size = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=0.9, alternative='two-sided')\n",
        "print(f'Required sample size to detect a 1 minute difference with 90% power: {sample_size:.2f}')"
      ],
      "metadata": {
        "id": "arRYnl9qz6VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neparametrické teyst a Levene mi tak trochu selhávají..."
      ],
      "metadata": {
        "id": "bIu8gzvUw5Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import fligner\n",
        "stat, p_value = fligner(type1, type2)\n",
        "print(f'Fligner-Killeen test for equal variances: Statistic = {stat}, p-value = {p_value}')"
      ],
      "metadata": {
        "id": "K4uFhBwnu53y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene\n",
        "levene(type1, type2)"
      ],
      "metadata": {
        "id": "U_7ff9bECT4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.30\n",
        "\n",
        "Front housings for cell phones are manufactured in an injection molding process. The time the part is allowed to cool in the mold before removal is thought to influence the occurrence of a particularly troublesome cosmetic defect, flow lines, in the finished housing. After manufacturing, the housings are inspected visually and assigned a score between 1 and 10 based on their appearance, with 10 corresponding to a perfect part and 1 corresponding to a completely defective part. An experiment was conducted using two cool-down times, 10 and 20 seconds, and 20 housings were evaluated at each level of cool-down time. All 40 observations in this experiment were run in random order.\n",
        "\n",
        "\n",
        "| 10s |||| 20s ||||\n",
        "|--------------------------------||||||||\n",
        "| 1 | 3 | 2 | 6 | 7 | 6 | 8 | 9 |\n",
        "| 1 | 5 | 3 | 3 | 5 | 5 | 9 | 7 |\n",
        "| 5 | 2 | 1 | 1 | 5 | 4 | 8 | 6 |\n",
        "| 5 | 6 | 2 | 8 | 6 | 8 | 4 | 5 |\n",
        "| 3 | 2 | 5 | 3 | 6 | 8 | 7 | 7 |\n",
        "\n",
        "\n",
        "* Is there evidence to support the claim that the longer cool-down time\n",
        "results in fewer appearance defects? Use $\\alpha = 0.05$.\n",
        "* What is the P-value for the test conducted in the previous part?\n",
        "* Find a 95 percent confidence interval on the difference in means. Provide\n",
        "a practical interpretation of this interval.\n",
        "* Compute the power of the test.\n"
      ],
      "metadata": {
        "id": "CU8aDa_V3y_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the URL\n",
        "url_30 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Ex02_30.csv\"\n",
        "df30 = pd.read_csv(url_30, sep=\";\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "df30.head()"
      ],
      "metadata": {
        "id": "OPmTG8WruIYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOLUTION:"
      ],
      "metadata": {
        "id": "rvOPQRe_65uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind, t\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "cooldown_10s = df30['10 seconds'].dropna().to_numpy()\n",
        "cooldown_20s = df30['20 seconds'].dropna().to_numpy()\n"
      ],
      "metadata": {
        "id": "1Lw60lOAt8AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a two-sample t-test to compare means\n",
        "t_stat, p_value = ttest_ind(cooldown_20s, cooldown_10s, equal_var=False)  # Assuming unequal variances\n",
        "print(f'T-statistic: {t_stat}, P-value: {p_value}')\n"
      ],
      "metadata": {
        "id": "RhKRY4hLCjlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean difference and the confidence interval for this difference\n",
        "mean_diff = np.mean(cooldown_20s) - np.mean(cooldown_10s)\n",
        "std_10s = np.std(cooldown_10s, ddof=1)\n",
        "std_20s = np.std(cooldown_20s, ddof=1)\n",
        "se_diff = np.sqrt((std_10s**2 / len(cooldown_10s)) + (std_20s**2 / len(cooldown_20s)))\n"
      ],
      "metadata": {
        "id": "cQxsDCl9Cj80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 95% Confidence Interval\n",
        "ci_lower = mean_diff - 1.96 * se_diff\n",
        "ci_upper = mean_diff + 1.96 * se_diff\n",
        "print(f'95% Confidence Interval for the mean difference: ({ci_lower}, {ci_upper})')\n"
      ],
      "metadata": {
        "id": "4AY_MVlWCkRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import t\n",
        "df = len(cooldown_20s) + len(cooldown_10s) - 2\n",
        "t_crit = t.ppf(0.975, df)  # 95% confidence level (two-tailed)\n",
        "\n",
        "# Confidence interval\n",
        "ci_low = mean_diff - t_crit * se_diff\n",
        "ci_high = mean_diff + t_crit * se_diff\n",
        "print(f\"95% Confidence Interval: ({ci_low}, {ci_high})\")\n"
      ],
      "metadata": {
        "id": "ThW1XdHGHRFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the power of the test\n",
        "effect_size = (np.mean(cooldown_20s) - np.mean(cooldown_10s)) / np.sqrt(((std_10s**2 + std_20s**2) / 2))\n",
        "analysis = TTestIndPower()\n",
        "power = analysis.power(effect_size=effect_size, nobs1=len(cooldown_10s), alpha=0.05, alternative='two-sided')\n",
        "print(f'Power of the test: {power}')"
      ],
      "metadata": {
        "id": "8_o7vHnACkjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "cm = sms.CompareMeans(sms.DescrStatsW(cooldown_20s), sms.DescrStatsW(cooldown_10s))\n",
        "\n",
        "# Get the 95% confidence interval\n",
        "conf_int = cm.tconfint_diff(usevar='unequal')  # For unequal variance (Welch's t-test)\n",
        "\n",
        "# Perform t-test\n",
        "from scipy.stats import ttest_ind\n",
        "t_stat, p_value = ttest_ind(cooldown_20s, cooldown_10s, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "print(f\"95% Confidence Interval: {conf_int}\")\n"
      ],
      "metadata": {
        "id": "pz_TKLbjGsoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t, ttest_ind\n",
        "\n",
        "# Assuming cooldown_20s and cooldown_10s are your datasets\n",
        "mean_diff = np.mean(cooldown_20s) - np.mean(cooldown_10s)\n",
        "\n",
        "# Calculate sample variances and sizes\n",
        "s1_squared = np.var(cooldown_20s, ddof=1)\n",
        "s2_squared = np.var(cooldown_10s, ddof=1)\n",
        "n1 = len(cooldown_20s)\n",
        "n2 = len(cooldown_10s)\n",
        "\n",
        "# Welch-Satterthwaite formula for degrees of freedom\n",
        "df = ((s1_squared/n1 + s2_squared/n2)**2) / ((s1_squared/n1)**2 / (n1 - 1) + (s2_squared/n2)**2 / (n2 - 1))\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = ttest_ind(cooldown_20s, cooldown_10s, equal_var=False)\n",
        "\n",
        "# Compute standard error of the difference\n",
        "se_diff = np.sqrt(s1_squared/n1 + s2_squared/n2)\n",
        "\n",
        "# Get the critical t-value\n",
        "t_crit = t.ppf(0.975, df)  # 95% confidence level (two-tailed)\n",
        "\n",
        "# Confidence interval\n",
        "ci_low = mean_diff - t_crit * se_diff\n",
        "ci_high = mean_diff + t_crit * se_diff\n",
        "\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "print(f\"95% Confidence Interval: ({ci_low}, {ci_high})\")\n"
      ],
      "metadata": {
        "id": "8PFoXaNxH3Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t, ttest_ind\n",
        "\n",
        "mean_diff = np.mean(cooldown_20s) - np.mean(cooldown_10s)\n",
        "\n",
        "# Calculate sample variances and sizes\n",
        "s1_squared = np.var(cooldown_20s, ddof=1)\n",
        "s2_squared = np.var(cooldown_10s, ddof=1)\n",
        "n1 = len(cooldown_20s)\n",
        "n2 = len(cooldown_10s)\n",
        "\n",
        "# Pooled variance formula\n",
        "s_p_squared = ((n1 - 1) * s1_squared + (n2 - 1) * s2_squared) / (n1 + n2 - 2)\n",
        "\n",
        "# Perform t-test assuming equal variance\n",
        "t_stat, p_value = ttest_ind(cooldown_20s, cooldown_10s, equal_var=True)\n",
        "\n",
        "# Compute standard error of the difference using pooled variance\n",
        "se_diff = np.sqrt(s_p_squared * (1/n1 + 1/n2))\n",
        "\n",
        "# Degrees of freedom\n",
        "df = n1 + n2 - 2\n",
        "\n",
        "# Get the critical t-value\n",
        "t_crit = t.ppf(0.975, df)  # 95% confidence level (two-tailed)\n",
        "\n",
        "# Confidence interval\n",
        "ci_low = mean_diff - t_crit * se_diff\n",
        "ci_high = mean_diff + t_crit * se_diff\n",
        "\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "print(f\"95% Confidence Interval: ({ci_low}, {ci_high})\")\n"
      ],
      "metadata": {
        "id": "AsAEngMQIXJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agLqRAysIp_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}