{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01NAEX/blob/main/code/01NAEX_Exercise_07_python_student_solution_PV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJRUeUJPrezp"
      },
      "source": [
        "\n",
        "# O1NAEX Exercise 07"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkkKD7h88ztb"
      },
      "outputs": [],
      "source": [
        "!pip install pyDOE3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def ensure_pkg(pkg_name: str) -> None:\n",
        "    # Install the package with pip if it is missing.\n",
        "    if importlib.util.find_spec(pkg_name) is None:\n",
        "        print(f\"Installing {pkg_name} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg_name])\n",
        "\n",
        "\n",
        "for package in (\"pyDOE3\",):\n",
        "    ensure_pkg(package)\n"
      ],
      "metadata": {
        "id": "avXNXA69ljh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyDOE3 import ff2n\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.graphics.factorplots import interaction_plot\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from scipy import stats as st\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "iOxWxGaNloef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def daniel_plot(effects, names):\n",
        "    effects = np.asarray(effects, dtype=float)\n",
        "    m = len(effects)\n",
        "    x = st.norm.ppf((np.arange(1, m + 1) - 0.5) / m)\n",
        "    order = np.argsort(effects)\n",
        "    y = effects[order]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(x, y)\n",
        "    lo, hi = int(0.25 * m), int(0.75 * m)\n",
        "    if hi > lo:\n",
        "        b, a = np.polyfit(x[lo:hi], y[lo:hi], 1)\n",
        "        xx = np.linspace(x.min(), x.max(), 200)\n",
        "        plt.plot(xx, a + b * xx, color=\"tab:red\", linewidth=1.2)\n",
        "    for xi, yi, nm in zip(x, y, [names[i] for i in order]):\n",
        "        plt.annotate(nm, (xi, yi), fontsize=8, textcoords=\"offset points\", xytext=(4, 4))\n",
        "    plt.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
        "    plt.xlabel(\"Normal quantiles\")\n",
        "    plt.ylabel(\"Effect\")\n",
        "    plt.title(\"Daniel plot\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def halfnormal_plot(effects, names):\n",
        "    effects = np.asarray(effects, dtype=float)\n",
        "    ae = np.abs(effects)\n",
        "    m = len(ae)\n",
        "    x = st.halfnorm.ppf((np.arange(1, m + 1) - 0.5) / m)\n",
        "    order = np.argsort(ae)\n",
        "    y = ae[order]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(x, y)\n",
        "    lo, hi = int(0.25 * m), int(0.75 * m)\n",
        "    if hi > lo:\n",
        "        b, a = np.polyfit(x[lo:hi], y[lo:hi], 1)\n",
        "        xx = np.linspace(x.min(), x.max(), 200)\n",
        "        plt.plot(xx, a + b * xx, color=\"tab:red\", linewidth=1.2)\n",
        "    idx_pos = {idx: pos for pos, idx in enumerate(order)}\n",
        "    for idx in order[-10:]:\n",
        "        pos = idx_pos[idx]\n",
        "        plt.annotate(names[idx], (x[pos], y[pos]), fontsize=8, textcoords=\"offset points\", xytext=(4, 4))\n",
        "    plt.xlabel(\"Half-normal quantiles\")\n",
        "    plt.ylabel(\"|Effect|\")\n",
        "    plt.title(\"Half-normal plot\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def lenth_pse(contrasts):\n",
        "    contrasts = np.asarray(contrasts, dtype=float)\n",
        "    s0 = 1.5 * np.median(np.abs(contrasts))\n",
        "    inlier_mask = np.abs(contrasts) < 2.5 * s0\n",
        "    pse = 1.5 * np.median(np.abs(contrasts[inlier_mask])) if np.any(inlier_mask) else s0\n",
        "    m = len(contrasts)\n",
        "    d = m / 3.0\n",
        "    ME = st.t.ppf(0.975, d) * pse\n",
        "    gamma = 1 - (1 + 0.95 ** (1 / m)) / 2\n",
        "    SME = st.t.ppf(1 - gamma, d) * pse\n",
        "    return pse, ME, SME\n",
        "\n",
        "\n",
        "def pareto_lenth(contrasts, names):\n",
        "    contrasts = np.asarray(contrasts, dtype=float)\n",
        "    pse, ME, SME = lenth_pse(contrasts)\n",
        "    order = np.argsort(np.abs(contrasts))\n",
        "    vals = np.abs(contrasts)[order]\n",
        "    labs = [names[i] for i in order]\n",
        "    y = np.arange(len(vals))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.barh(y, vals, color=\"tab:blue\")\n",
        "    plt.axvline(ME, color=\"tab:red\", linestyle=\"--\", label=\"ME\")\n",
        "    plt.axvline(SME, color=\"tab:orange\", linestyle=\":\", label=\"SME\")\n",
        "    plt.yticks(y, labs)\n",
        "    plt.xlabel(\"|contrast|\")\n",
        "    plt.title(\"Pareto (Lenth)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    return pse, ME, SME\n",
        "\n",
        "\n",
        "def contour_slices(model, x_var, y_var, fixed_var, fixed_levels, grid_points=41, cmap=\"viridis\", title=\"\"):\n",
        "    all_vars = {\"A_num\", \"C_num\", \"D_num\"}\n",
        "    xs = np.linspace(-1, 1, grid_points)\n",
        "    ys = np.linspace(-1, 1, grid_points)\n",
        "    X, Y = np.meshgrid(xs, ys)\n",
        "    fig, axes = plt.subplots(1, len(fixed_levels), figsize=(5 * len(fixed_levels), 4), sharex=True, sharey=True)\n",
        "    if not isinstance(axes, np.ndarray):\n",
        "        axes = np.array([axes])\n",
        "    levels = None\n",
        "    cs = None\n",
        "\n",
        "    for ax, lvl in zip(axes, fixed_levels):\n",
        "        data = pd.DataFrame({x_var: X.ravel(), y_var: Y.ravel()})\n",
        "        for var in all_vars - {x_var, y_var, fixed_var}:\n",
        "            data[var] = 0.0\n",
        "        data[fixed_var] = lvl\n",
        "        Z = model.predict(data).to_numpy().reshape(X.shape)\n",
        "        if levels is None:\n",
        "            levels = np.linspace(Z.min(), Z.max(), 20)\n",
        "        cs = ax.contourf(xs, ys, Z, levels=levels, cmap=cmap)\n",
        "        ax.set_title(f\"{fixed_var.replace('_num', '').upper()} = {lvl}\")\n",
        "        ax.set_xlabel(x_var.replace('_num', ''))\n",
        "        ax.set_ylabel(y_var.replace('_num', ''))\n",
        "\n",
        "    fig.suptitle(title)\n",
        "    if cs is not None:\n",
        "        fig.colorbar(cs, ax=axes.ravel().tolist(), label=\"Predicted Rate\")\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "ZQBe3BwplxPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc40031"
      },
      "source": [
        "## Problem 6.31 + 6.32\n",
        "\n",
        "from the chapter 6, D. C. Montgomery DAoE - 8. edition.\n",
        "\n",
        "An experiment was conducted on a chemical process that produces a\n",
        "polymer. The four factors studied were temperature (A), catalyst\n",
        "concentration (B), time (C), and pressure (D). Two responses, molecular\n",
        "weight and viscosity, were observed. The design matrix and response data\n",
        "are following:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Rerun the analysis from previous lecture with centerpoints."
      ],
      "metadata": {
        "id": "5gPcv5pa7UYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADLJuBchGazL"
      },
      "outputs": [],
      "source": [
        "df631 = pd.read_csv(\"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Problem_6_31.txt\", sep=\";\")\n",
        "df631"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoI3IPGI3X25"
      },
      "outputs": [],
      "source": [
        "m = ff2n(4)\n",
        "m = m[:, ::-1]\n",
        "\n",
        "m_df = pd.DataFrame(m, columns=[\"A\", \"B\", \"C\", \"D\"])\n",
        "print(m_df)\n",
        "Weight = df631.loc[0:15, \"Weight\"].values\n",
        "Viscosity = df631.loc[0:15, \"Viscosity\"].values\n",
        "m_df['Weight'] = Weight\n",
        "m_df['Viscosity'] = Viscosity\n",
        "response_names = m_df.columns[-2:].tolist()\n",
        "\n",
        "print(\"Response names:\", response_names)\n",
        "print(m_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "\n",
        "# We infer centers from the data structure (midpoint of factorial range)\n",
        "# A: Temp (100, 120) -> Center 110, Step 10\n",
        "# B: Conc (4, 8) -> Center 6, Step 2\n",
        "# C: Time (20, 30) -> Center 25, Step 5\n",
        "# D: Pressure (60, 75) -> Center 67.5, Step 7.5\n",
        "\n",
        "df_coded = df631.copy()\n",
        "df_coded['A'] = (df631['Temperature'] - 110) / 10\n",
        "df_coded['B'] = (df631['Concentration'] - 6) / 2\n",
        "df_coded['C'] = (df631['Time'] - 25) / 5\n",
        "df_coded['D'] = (df631['Pressure'] - 67.5) / 7.5\n",
        "\n",
        "# Split factorial and center points\n",
        "df_fact = df_coded.iloc[:16]\n",
        "df_cent = df_coded.iloc[16:]\n",
        "\n",
        "#  MOLECULAR WEIGHT\n",
        "\n",
        "# daniel plot\n",
        "model_mw_full = smf.ols(\"Weight ~ A*B*C*D\", data=df_fact).fit()\n",
        "effects_mw = model_mw_full.params.drop(\"Intercept\") * 2\n",
        "effect_names = [term.replace(\":\", \"\").replace(\"[T.1.0]\", \"\") for term in effects_mw.index]\n",
        "daniel_plot(effects_mw.values, effect_names)\n",
        "\n",
        "# Refined Model\n",
        "model_mw_reduced = smf.ols(\"Weight ~ A + B + C + A:B\", data=df_coded).fit()\n",
        "print(\"\\nMW ANOVA (Refined with C):\")\n",
        "print(sm.stats.anova_lm(model_mw_reduced, typ=1))\n",
        "\n",
        "\n",
        "model_visc_full = smf.ols(\"Viscosity ~ A*B*C*D\", data=df_fact).fit()\n",
        "effects_visc = model_visc_full.params.drop(\"Intercept\") * 2\n",
        "effect_names = [term.replace(\":\", \"\").replace(\"[T.1.0]\", \"\") for term in effects_visc.index]\n",
        "daniel_plot(effects_visc.values, effect_names)\n",
        "\n",
        "# Refined Model\n",
        "model_visc_reduced = smf.ols(\"Viscosity ~ A + B\", data=df_coded).fit()\n",
        "print(\"\\nViscosity ANOVA:\")\n",
        "print(sm.stats.anova_lm(model_visc_reduced, typ=1))\n",
        "\n"
      ],
      "metadata": {
        "id": "hT2MbhLSbqTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_vals = np.linspace(-1.5, 1.5, 100)\n",
        "b_vals = np.linspace(-1.5, 1.5, 100)\n",
        "AA, BB = np.meshgrid(a_vals, b_vals)\n",
        "\n",
        "pred_df = pd.DataFrame({'A': AA.ravel(), 'B': BB.ravel(), 'C': 0, 'D': 0})\n",
        "\n",
        "mw_pred = model_mw_reduced.predict(pred_df).values.reshape(AA.shape)\n",
        "visc_pred = model_visc_reduced.predict(pred_df).values.reshape(AA.shape)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# 1. Viscosity (Background Color)\n",
        "cp = ax.contourf(AA, BB, visc_pred, cmap='viridis', levels=20)\n",
        "fig.colorbar(cp, label='Viscosity')\n",
        "\n",
        "# 2. Molecular Weight (The Constraints)\n",
        "# Dashed white lines for the target 2400 and 2500\n",
        "cs = ax.contour(AA, BB, mw_pred, levels=[2400, 2500], colors='white', linewidths=3, linestyles='dashed')\n",
        "ax.clabel(cs, fmt='%1.0f')\n",
        "\n",
        "# 3. Highlight the \"Sweet Spot\"\n",
        "# Hatched region for the valid MW band\n",
        "ax.contourf(AA, BB, mw_pred, levels=[2400, 2500], colors='none', hatches=['//'], alpha=0.3)\n",
        "\n",
        "ax.set_xlabel('Temperature (A)')\n",
        "ax.set_ylabel('Concentration (B)')\n",
        "ax.set_title('Optimization: Minimize Viscosity within MW Target (2400-2500)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VFPh08VNWNTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# 1. Define Factorial and Center Sets\n",
        "# Rows 0-15 are factorial, 16-19 are center points\n",
        "y_fact_mw = df631['Weight'].iloc[:16]\n",
        "y_cent_mw = df631['Weight'].iloc[16:]\n",
        "\n",
        "y_fact_visc = df631['Viscosity'].iloc[:16]\n",
        "y_cent_visc = df631['Viscosity'].iloc[16:]\n",
        "def test_curvature(y_fact, y_cent, name):\n",
        "    # Calculate Means\n",
        "    mean_f = y_fact.mean()\n",
        "    mean_c = y_cent.mean()\n",
        "\n",
        "    mse_pure = y_cent.var(ddof=1)\n",
        "\n",
        "    # Calculate Contrast and SS_Curvature\n",
        "    n_f = len(y_fact)\n",
        "    n_c = len(y_cent)\n",
        "    ss_curve = (n_f * n_c * (mean_f - mean_c)**2) / (n_f + n_c)\n",
        "\n",
        "    # F-Test\n",
        "    f_0 = ss_curve / mse_pure\n",
        "    p_val = 1 - stats.f.cdf(f_0, 1, n_c - 1)\n",
        "\n",
        "    print(f\"--- Curvature Test: {name} ---\")\n",
        "    print(f\"Mean Factorial: {mean_f:.2f}\")\n",
        "    print(f\"Mean Center:    {mean_c:.2f}\")\n",
        "    print(f\"SS Curvature:   {ss_curve:.4f}\")\n",
        "    print(f\"F stat:         {f_0:.2f}\")\n",
        "    print(f\"P-value:        {p_val:.4f}\")\n",
        "\n",
        "\n",
        "test_curvature(y_fact_mw, y_cent_mw, \"Molecular Weight\")\n",
        "test_curvature(y_fact_visc, y_cent_visc, \"Viscosity\")"
      ],
      "metadata": {
        "id": "T_5_R7ISaqkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear model is sufficient for both cases. The hypothesis cannot be rejected."
      ],
      "metadata": {
        "id": "7GifVU2Ab2By"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lYQT0wrrb3V"
      },
      "source": [
        "##\tProblems 6.26 and 6.27 and 7.7\n",
        "from the chapters 6 and 7, D. C. Montgomery DAoE - 8. edition.\n",
        "\n",
        "An experiment was run in a semiconductor fabrication plant in an effort to increase yield. Five factors, each at two levels, were studied. The factors (and levels) were\n",
        "+ A = aperture setting (small, large),\n",
        "+ B = exposure time (20% below nominal, 20% above nominal),\n",
        "+ C = development time (30 and 45 s),\n",
        "+ D = mask dimension (small, large), and\n",
        "+ E = etch time (14.5 and 15.5min).\n",
        "\n",
        "The unreplicated $2^5$ design shown below was run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxE90Ksc9Pzi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df626 = pd.read_csv(\"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Ex06_26.csv\", sep=\";\")\n",
        "df626"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxD9HMoPrbHg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define new column names\n",
        "new_column_names = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
        "\n",
        "# Rename columns\n",
        "df626.rename(columns=dict(zip(df626.columns, new_column_names)), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJG1mrLI3X26"
      },
      "outputs": [],
      "source": [
        "df626.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lVHpPgSX3X26"
      },
      "outputs": [],
      "source": [
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# Rename variable values\n",
        "df626[\"B\"] = df626[\"B\"].apply(lambda x: -1.0 if x < 15 else 1.0)\n",
        "df626[\"E\"] = df626[\"E\"].apply(lambda x: -1.0 if x < 15 else 1.0)\n",
        "df626[\"C\"] = df626[\"C\"].apply(lambda x: -1.0 if x < 40 else 1.0)\n",
        "\n",
        "df626[\"A\"] = df626[\"A\"].replace({\"small\": -1.0, \"large\": 1.0}).infer_objects(copy=False)\n",
        "df626[\"D\"] = df626[\"D\"].replace({\"Small\": -1.0, \"Large\": 1.0}).infer_objects(copy=False)\n",
        "\n",
        "# Change data types to categorical\n",
        "df626[new_column_names] = df626[new_column_names].astype(\"category\")\n",
        "\n",
        "# View the renamed dataframe\n",
        "df626.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8JzXtJC3X26"
      },
      "outputs": [],
      "source": [
        "df626.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmkF7D7s3X26"
      },
      "outputs": [],
      "source": [
        "df626_cp = df626.iloc[-4:] # Center points\n",
        "df626_df = df626.iloc[:-4] # Working points"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df626_cp"
      ],
      "metadata": {
        "id": "8qHXbUN7Wqn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df626_df)"
      ],
      "metadata": {
        "id": "f1RDS3jYjjv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Construct a normal probability plot of the effect estimates.\n",
        "    Which effects appear to be large?\n",
        "\n",
        "(b) Conduct an analysis of variance to confirm your findings\n",
        "    for part (a).\n",
        "\n",
        "(c) Write down the regression model relating yield to the\n",
        "    significant process variables.\n",
        "\n",
        "(d) Plot the residuals on normal probability paper. Is the\n",
        "    plot satisfactory?\n",
        "\n",
        "(e) Plot the residuals versus the predicted yields and versus\n",
        "    each of the five factors. Comment on the plots.\n",
        "\n",
        "(f) Interpret any significant interactions.\n",
        "\n",
        "(g) What are your recommendations regarding process\n",
        "    operating conditions?\n",
        "\n",
        "(h) Project the 2^5 design in this problem into a 2^k design\n",
        "    in the important factors. Sketch the design and show.\n",
        "\n",
        "(i) Suppose that the experimenter had run four center points\n",
        "    in addition to the 32 trials in the original experiment.\n",
        "    The yields obtained at the center point runs were 68, 74,\n",
        "    76, and 70. Reanalyze the experiment, including a test for\n",
        "    pure quadratic curvature. Discuss what your next step\n",
        "    should be.\n",
        "\n",
        "(j) Construct and analyze a design in two blocks with ABCDE\n",
        "confounded with blocks.\n",
        "\n",
        "(k) Assuming now that four blocks are necessary. Suggest a reasonable confounding scheme.\n",
        "\n",
        "(l) Suppose that it was necessary to run this design in four blocks with ACDE and BCD (and consequently ABE) confounded. Analyze the data from this design.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtQNV83q5_kU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Construct a normal probability plot of the effect estimates.\n",
        "    Which effects appear to be large?"
      ],
      "metadata": {
        "id": "M0cCPKL6xDgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItOQptXA3X3E"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as ols\n",
        "\n",
        "formula = \"Yield_dbl ~ (A + B + C + D + E)**4\"\n",
        "effects_model = smf.ols(formula, data=df626_df.assign(Yield_dbl=2 * df626_df[\"Yield\"])).fit()\n",
        "\n",
        "# 2. Extract Effects\n",
        "# In a 2^k design (numeric -1/+1): Effect = 2 * Beta_Coefficient\n",
        "effects = effects_model.params.drop(\"Intercept\")\n",
        "# 3. Clean Names\n",
        "# statsmodels uses \":\" for interaction (A:B). Your replace fixes this.\n",
        "effect_names = [term.replace(\":\", \"\").replace(\"[T.1.0]\", \"\") for term in effects.index]\n",
        "\n",
        "# 4. Create Table for inspection\n",
        "effect_table = pd.DataFrame({\"effect\": effects.values}, index=effect_names)\n",
        "print(effect_table.sort_values(by=\"effect\"))\n",
        "\n",
        "# 5. Plot\n",
        "daniel_plot(effects.values, effect_names)\n",
        "halfnormal_plot(effects.values, effect_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most important are the factors C and B and interaction AB, thus we include the A aswell to have hierarchical model\n",
        "\n"
      ],
      "metadata": {
        "id": "HccaZtrEsNPk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUj9wgRhpnDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Conduct an analysis of variance to confirm your findings\n",
        "    for part (a)."
      ],
      "metadata": {
        "id": "32nPI-Muw-49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "model_reduced = smf.ols('Yield ~ A * B  + C', data=df626_df).fit()\n",
        "sm.stats.anova_lm(model_reduced, typ=2)"
      ],
      "metadata": {
        "id": "Oz-mBf9Cpjyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Write down the regression model relating yield to the\n",
        "    significant process variables.\n"
      ],
      "metadata": {
        "id": "4qeh67FO0U3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_reduced.summary()"
      ],
      "metadata": {
        "id": "C1cv0AwR0Aec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Plot the residuals on normal probability paper. Is the\n",
        "    plot satisfactory?"
      ],
      "metadata": {
        "id": "aEEAx1SP0iPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Get Residuals from your reduced model\n",
        "# (Assuming model_reduced = smf.ols('Yield ~ A + B + C + A:B', data=df626_df).fit())\n",
        "residuals = model_reduced.resid\n",
        "\n",
        "# 2. Generate the QQ Plot\n",
        "# line='s' fits a line to the standardized residuals (expected vs theoretical)\n",
        "fig = sm.qqplot(residuals, line='s')\n",
        "plt.title(\"Normal Probability Plot of Residuals\")\n",
        "plt.show()\n",
        "# Optional: Shapiro-Wilk Test for numeric confirmation\n",
        "from scipy import stats\n",
        "shapiro_test = stats.shapiro(residuals)\n",
        "print(f\"Shapiro-Wilk p-value: {shapiro_test.pvalue:.4f}\")"
      ],
      "metadata": {
        "id": "GXUFghHg0ifE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good"
      ],
      "metadata": {
        "id": "934RjHiH3tNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Plot the residuals versus the predicted yields and versus\n",
        "    each of the five factors. Comment on the plots.\n",
        "\n"
      ],
      "metadata": {
        "id": "t-VxDao_3vTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get residuals and predictions\n",
        "residuals = model_reduced.resid\n",
        "predicted = model_reduced.fittedvalues\n",
        "factors = ['A', 'B', 'C', 'D', 'E']\n",
        "\n",
        "# 1. Residuals vs. Predicted\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(predicted, residuals, alpha=0.7)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Predicted Yield\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residuals vs. Predicted\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 2. Residuals vs. Factors\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 4), sharey=True)\n",
        "for ax, factor in zip(axes, factors):\n",
        "    sns.stripplot(x=df626_df[factor], y=residuals, ax=ax, jitter=True)\n",
        "    ax.axhline(0, color='red', linestyle='--')\n",
        "    ax.set_title(f\"Resid vs {factor}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5hZ4SjiM1WZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hb90mU5U79kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(g) What are your recommendations regarding process\n",
        "    operating conditions?"
      ],
      "metadata": {
        "id": "G03ffpwa5Kh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "factor_cols = list(\"ABCDE\")\n",
        "fig, axes = plt.subplots(1, 5, figsize=(22, 4), sharey=True)\n",
        "for ax, factor in zip(axes.flat, factor_cols):\n",
        "    means = df626_df.groupby(factor, observed=True)[\"Yield\"].mean().sort_index()\n",
        "    ax.plot(means.index, means.values, marker=\"o\")\n",
        "    ax.set_title(f\"Main effect: {factor}\")\n",
        "    ax.set_xlabel(f\"{factor} level\")\n",
        "    ax.set_ylabel(\"Mean Rate\")\n",
        "fig.suptitle(\"Main effects on filtration rate\", y=1.02)\n",
        "plt.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "yDSKAy5i5wCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "pairs = list(itertools.combinations(factor_cols, 2))\n",
        "fig, axes = plt.subplots(2, 5, figsize=(20, 8), sharey=True)\n",
        "\n",
        "for ax, (f1, f2) in zip(axes.flat, pairs):\n",
        "    interaction_plot(\n",
        "        df626_df[f1],\n",
        "        df626_df[f2],\n",
        "        df626_df[\"Yield\"],\n",
        "        ax=ax,\n",
        "        colors=[\"tab:blue\", \"tab:orange\"]\n",
        "    )\n",
        "    ax.set_title(f\"{f1} x {f2}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mg6-o1JT5_PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(f) Interpret any significant interactions.\n",
        "\n",
        "A:B - exposure*aperture\n",
        "Higher aperture A=1 need more light and profit more from longer exposures"
      ],
      "metadata": {
        "id": "dTvxVJAi9c0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My recomendation is to use large aperture setting and long exposure"
      ],
      "metadata": {
        "id": "GjXrdPgn4_Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-0z3Ga_4Zxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(h) Project the 2^5 design in this problem into a 2^k design\n",
        "    in the important factors. Sketch the design and show.\n",
        "\n"
      ],
      "metadata": {
        "id": "aLT0XIme9mBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projected_design = df626_df.groupby(['A', 'B', 'C'])['Yield'].agg(['count', 'mean', 'std'])\n",
        "\n",
        "print(\"Projected 2^3 Design (with Replicates):\")\n",
        "print(projected_design)"
      ],
      "metadata": {
        "id": "Ri548pMY9v_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Suppose that the experimenter had run four center points\n",
        "    in addition to the 32 trials in the original experiment.\n",
        "    The yields obtained at the center point runs were 68, 74,\n",
        "    76, and 70. Reanalyze the experiment, including a test for\n",
        "    pure quadratic curvature. Discuss what your next step\n",
        "    should be.\n"
      ],
      "metadata": {
        "id": "IYZF6i1N9l_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "y_fact = df626_df['Yield']\n",
        "y_cent = df626_cp['Yield']\n",
        "\n",
        "test_curvature(y_cent=y_cent, y_fact=y_fact, name=\"yield\")"
      ],
      "metadata": {
        "id": "AjSVfowr-Dfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6XWQBlXc-Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The curvature test is highly significant (F stat 458,p<.001), with center points 41.5 units higher than the factorial points. The linear model is inadequate. My instinct is adding polynomial features $A^2$, $B^2$ etc. Gemini suggested: \"The next step is to augment the current design with axial runs to form a Central Composite Design\""
      ],
      "metadata": {
        "id": "GwHTInO8-bum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "(j) Construct and analyze a design in two blocks with ABCDE\n",
        "confounded with blocks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oo5aNMTu9l8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_num(series):\n",
        "    return series.astype(float)\n",
        "\n",
        "# 2. Calculate the Interaction Sign\n",
        "interaction_sign = (\n",
        "    to_num(df626_df['A']) *\n",
        "    to_num(df626_df['B']) *\n",
        "    to_num(df626_df['C']) *\n",
        "    to_num(df626_df['D']) *\n",
        "    to_num(df626_df['E'])\n",
        ")\n",
        "\n",
        "# 3. Assign Blocks\n",
        "# If product is positive (+1) -> Block 1\n",
        "# If product is negative (-1) -> Block 2\n",
        "df626_df = df626_df.copy()\n",
        "\n",
        "# Now this line won't throw a warning\n",
        "df626_df['Block'] = interaction_sign.apply(lambda x: 'Block_1' if x > 0 else 'Block_2')\n",
        "\n",
        "# 4. Check the split (Should be exactly 16 and 16)\n",
        "print(df626_df['Block'].value_counts())\n",
        "\n",
        "# 5. Run the ANOVA\n",
        "# 'C(Block)' tells statsmodels to treat Block as a categorical grouping factor\n",
        "formula_blocked = \"Yield ~ Block + A + B + C + A:B\"\n",
        "\n",
        "model_blocked = smf.ols(formula_blocked, data=df626_df).fit()\n",
        "anova_blocked = anova_lm(model_blocked, typ=1)\n",
        "\n",
        "print(anova_blocked)"
      ],
      "metadata": {
        "id": "T-9DlcGOAXpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no significant difference between the two blocks."
      ],
      "metadata": {
        "id": "KCefu8MpNBVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(k) Assuming now that four blocks are necessary. Suggest a reasonable confounding scheme.\n",
        "\n"
      ],
      "metadata": {
        "id": "I0le2uvI9l5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daniel_plot(effects.values, effect_names)"
      ],
      "metadata": {
        "id": "DwRevau3O1rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block by the interactions ABDE and BCE as they seems influential in Daniel plot."
      ],
      "metadata": {
        "id": "3LYM16gxO4rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator 1: ABDE\n",
        "sign_ABDE = to_num(df626_df['A']) * to_num(df626_df['B']) * to_num(df626_df['D']) * to_num(df626_df['E'])\n",
        "\n",
        "# Generator 2: BCE\n",
        "sign_BCE = to_num(df626_df['B']) * to_num(df626_df['C']) * to_num(df626_df['E'])\n",
        "\n",
        "# 3. Assign Blocks based on the (ADE, BCE) tuple\n",
        "def assign_4_blocks(row_idx):\n",
        "    s1 = sign_ABDE[row_idx]\n",
        "    s2 = sign_BCE[row_idx]\n",
        "\n",
        "    if s1 > 0 and s2 > 0: return 'Block_1'\n",
        "    if s1 < 0 and s2 > 0: return 'Block_2'\n",
        "    if s1 > 0 and s2 < 0: return 'Block_3'\n",
        "    return 'Block_4' # (-1, -1)\n",
        "\n",
        "df626_df['Block4'] = [assign_4_blocks(i) for i in df626_df.index]\n",
        "\n",
        "# 4. Verify Balance (Should be 8 runs per block)\n",
        "print(df626_df['Block4'].value_counts())\n",
        "\n",
        "# 5. ANOVA\n",
        "# Note: 'Block4' automatically absorbs ADE, BCE, and ABCD variance.\n",
        "# Do NOT put those terms in the formula.\n",
        "formula_4blocks = \"Yield ~ Block4 + A + B + C + A:B\"\n",
        "model_4blocks = smf.ols(formula_4blocks, data=df626_df).fit()\n",
        "\n",
        "print(sm.stats.anova_lm(model_4blocks, typ=1))"
      ],
      "metadata": {
        "id": "gU7h8i0GIJh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(l) Suppose that it was necessary to run this design in four blocks with ACDE and BCD (and consequently ABE) confounded. Analyze the data from this design."
      ],
      "metadata": {
        "id": "PgkQv5wA9lxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# 1. Define Helper for Numeric Conversion\n",
        "def to_num(series):\n",
        "    return series.astype(float)\n",
        "\n",
        "# 2. Calculate Generator Signs\n",
        "# Generator 1: ACDE\n",
        "sign_ACDE = (to_num(df626_df['A']) * to_num(df626_df['C']) * to_num(df626_df['D']) * to_num(df626_df['E']))\n",
        "\n",
        "# Generator 2: BCD\n",
        "sign_BCD = (to_num(df626_df['B']) * to_num(df626_df['C']) * to_num(df626_df['D']))\n",
        "\n",
        "# 3. Assign 4 Blocks based on signs\n",
        "def assign_custom_blocks(row_idx):\n",
        "    s1 = sign_ACDE[row_idx]\n",
        "    s2 = sign_BCD[row_idx]\n",
        "\n",
        "    if s1 > 0 and s2 > 0: return 'Block_1'\n",
        "    if s1 < 0 and s2 > 0: return 'Block_2'\n",
        "    if s1 > 0 and s2 < 0: return 'Block_3'\n",
        "    return 'Block_4' # (-1, -1)\n",
        "\n",
        "df626_df['Block_L'] = [assign_custom_blocks(i) for i in df626_df.index]\n",
        "\n",
        "print(\"Runs per Block:\", df626_df['Block_L'].value_counts())\n",
        "\n",
        "# The variance of ABE, BCD, and ACDE is now captured in \"Block_L\"\n",
        "formula_L = \"Yield ~ Block_L + A + B + C + A:B\"\n",
        "model_L = smf.ols(formula_L, data=df626_df).fit()\n",
        "\n",
        "print(anova_lm(model_L, typ=1))"
      ],
      "metadata": {
        "id": "DpLNxmPYIaa5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "NAEX01",
      "language": "python",
      "name": "naex01"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}