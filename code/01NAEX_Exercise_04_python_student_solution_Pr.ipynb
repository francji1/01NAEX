{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01NAEX/blob/main/code/01NAEX_Exercise_04_python_student_solution_Pr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJRUeUJPrezp"
      },
      "source": [
        "\n",
        "# O1NAEX Exercise 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEGyKc3C8teG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:33.993006Z",
          "iopub.status.busy": "2025-10-16T06:45:33.992645Z",
          "iopub.status.idle": "2025-10-16T06:45:33.997825Z",
          "shell.execute_reply": "2025-10-16T06:45:33.997248Z"
        },
        "id": "26cEQ8Nt8teK"
      },
      "outputs": [],
      "source": [
        "# Skipped: !pip install rpy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:34.000472Z",
          "iopub.status.busy": "2025-10-16T06:45:34.000282Z",
          "iopub.status.idle": "2025-10-16T06:45:34.002426Z",
          "shell.execute_reply": "2025-10-16T06:45:34.002035Z"
        },
        "id": "vCDVk5ts8teL"
      },
      "outputs": [],
      "source": [
        "# Skipped: %load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-tQykDJeaY9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:34.004630Z",
          "iopub.status.busy": "2025-10-16T06:45:34.004439Z",
          "iopub.status.idle": "2025-10-16T06:45:35.620535Z",
          "shell.execute_reply": "2025-10-16T06:45:35.620180Z"
        },
        "id": "AzDtqykGeacb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, t\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:35.622900Z",
          "iopub.status.busy": "2025-10-16T06:45:35.622747Z",
          "iopub.status.idle": "2025-10-16T06:45:35.904584Z",
          "shell.execute_reply": "2025-10-16T06:45:35.904332Z"
        },
        "id": "a7zFYA4nIC38"
      },
      "outputs": [],
      "source": [
        "# Recap of the Lecture in Python\n",
        "\n",
        "# Read the data from the URL with fallback to local file\n",
        "import os\n",
        "\n",
        "rocket_path_url = \"https://raw.githubusercontent.com/francji1/01NAEX/refs/heads/main/data/rocket2.txt\"\n",
        "rocket_path_local = \"/Users/michalprusek/PycharmProjects/01NAEX/data/rocket2.txt\"\n",
        "\n",
        "try:\n",
        "    rocket = pd.read_csv(rocket_path_url, sep=\";\")\n",
        "    print(\"Data loaded from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load from GitHub: {e}\")\n",
        "    print(\"Loading from local file...\")\n",
        "    rocket = pd.read_csv(rocket_path_local, sep=\";\")\n",
        "    print(\"Data loaded from local file\")\n",
        "\n",
        "# Renaming columns for consistency\n",
        "rocket.rename(columns={'op': 'operator', 'y': 'Propellant'}, inplace=True)\n",
        "\n",
        "# Converting columns to factors (categorical variables)\n",
        "rocket['operator'] = rocket['operator'].astype('category')\n",
        "rocket['batch'] = rocket['batch'].astype('category')\n",
        "\n",
        "# Latin Square Design Plotting\n",
        "sns.boxplot(x='operator', y='Propellant', data=rocket)\n",
        "plt.title('Propellant by Operator')\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='batch', y='Propellant', data=rocket)\n",
        "plt.title('Propellant by Batch')\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='treat', y='Propellant', data=rocket)\n",
        "plt.title('Propellant by Treatment')\n",
        "plt.show()\n",
        "\n",
        "# Latin Square Design - Linear Model\n",
        "rocket_lm = smf.ols('Propellant ~ operator + batch + treat', data=rocket).fit()\n",
        "print(\"\\n=== ANOVA with operator, batch, and treat = 4×4 Latin Square ===\")\n",
        "print(sm.stats.anova_lm(rocket_lm))\n",
        "\n",
        "# Without considering batch as a factor\n",
        "rocket_lm2 = smf.ols('Propellant ~ operator + treat', data=rocket).fit()\n",
        "print(\"\\n=== ANOVA without batch = RCBD ===\")\n",
        "print(sm.stats.anova_lm(rocket_lm2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lYQT0wrrb3V"
      },
      "source": [
        "\n",
        "##\tProblem 4.23\n",
        "from the chapter 4, D. C. Montgomery DAoE - 8. edition.\n",
        "\n",
        "An industrial engineer is investigating the effect of\n",
        "four assembly methods (A, B, C, D) on the assembly time for\n",
        "a color television component. Four operators are selected for\n",
        "the study. Furthermore, the engineer knows that each assembly\n",
        "method produces such fatigue that the time required for\n",
        "the last assembly may be greater than the time required for the\n",
        "first, regardless of the method. That is, a trend develops in the\n",
        "required assembly time. To account for this source of variability,\n",
        "the engineer uses the Latin square design shown below.\n",
        "Analyze the data from this experiment (use\t$\\alpha = 0.05$) and draw\n",
        "appropriate conclusions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:35.905865Z",
          "iopub.status.busy": "2025-10-16T06:45:35.905775Z",
          "iopub.status.idle": "2025-10-16T06:45:35.954201Z",
          "shell.execute_reply": "2025-10-16T06:45:35.953856Z"
        },
        "id": "NEM0lHPvWZ0w"
      },
      "outputs": [],
      "source": [
        "# Read the data from the URL with fallback to local file\n",
        "url_4_23 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Problem_4_23.txt\"\n",
        "local_4_23 = \"/Users/michalprusek/PycharmProjects/01NAEX/data/Problem_4_23.txt\"\n",
        "\n",
        "try:\n",
        "    df_4_23 = pd.read_csv(url_4_23, sep=\";\")\n",
        "    print(\"Data loaded from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load from GitHub: {e}\")\n",
        "    print(\"Loading from local file...\")\n",
        "    df_4_23 = pd.read_csv(local_4_23, sep=\";\")\n",
        "    print(\"Data loaded from local file\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(\"\\n=== Problem 4.23 Data ===\")\n",
        "print(df_4_23.head())\n",
        "print(f\"\\nData shape: {df_4_23.shape}\")\n",
        "print(f\"\\nColumns: {df_4_23.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOMgbk3TZh4X"
      },
      "source": [
        "### Problem 4.23 - Analysis\n",
        "\n",
        "**Latin Square Design:** 4 assembly methods (A, B, C, D) × 4 operators × 4 orders\n",
        "\n",
        "This is a Latin Square design where:\n",
        "- **Treatments**: Assembly methods (A, B, C, D)\n",
        "- **Row blocking factor**: Order (1-4, accounts for fatigue effect)\n",
        "- **Column blocking factor**: Operator (1-4)\n",
        "\n",
        "We will perform ANOVA with α = 0.05 and draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2upiZejJZh4X"
      },
      "outputs": [],
      "source": [
        "# Problem 4.23 - Latin Square Analysis\n",
        "from scipy import stats\n",
        "\n",
        "# Convert columns to categorical\n",
        "df_4_23['Operator'] = df_4_23['Operator'].astype('category')\n",
        "df_4_23['Order'] = df_4_23['Order'].astype('category')\n",
        "df_4_23['Method'] = df_4_23['Method'].astype('category')\n",
        "\n",
        "# Summary statistics\n",
        "print(\"=== Summary Statistics by Assembly Method ===\")\n",
        "print(df_4_23.groupby('Method', observed=True)['Time'].describe())\n",
        "\n",
        "print(\"\\n=== Summary Statistics by Operator ===\")\n",
        "print(df_4_23.groupby('Operator', observed=True)['Time'].describe())\n",
        "\n",
        "print(\"\\n=== Summary Statistics by Order ===\")\n",
        "print(df_4_23.groupby('Order', observed=True)['Time'].describe())\n",
        "\n",
        "# Check the design structure (Latin square)\n",
        "print(\"\\n=== Latin Square Structure ===\")\n",
        "print(pd.crosstab(df_4_23['Operator'], df_4_23['Order'], values=df_4_23['Method'], aggfunc=lambda x: x.iloc[0]))\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "sns.boxplot(x='Method', y='Time', data=df_4_23, ax=axes[0])\n",
        "axes[0].set_title('Assembly Time by Method')\n",
        "axes[0].set_ylabel('Time')\n",
        "\n",
        "sns.boxplot(x='Operator', y='Time', data=df_4_23, ax=axes[1])\n",
        "axes[1].set_title('Assembly Time by Operator')\n",
        "axes[1].set_ylabel('Time')\n",
        "\n",
        "sns.boxplot(x='Order', y='Time', data=df_4_23, ax=axes[2])\n",
        "axes[2].set_title('Assembly Time by Order (Fatigue Effect)')\n",
        "axes[2].set_ylabel('Time')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Latin Square ANOVA Model\n",
        "model_4_23 = smf.ols('Time ~ Operator + Order + Method', data=df_4_23).fit()\n",
        "anova_4_23 = sm.stats.anova_lm(model_4_23, typ=2)\n",
        "\n",
        "print(\"\\n=== ANOVA Table (Latin Square Design) ===\")\n",
        "print(anova_4_23)\n",
        "print(f\"\\nModel R-squared: {model_4_23.rsquared:.4f}\")\n",
        "\n",
        "# Test for significance at α = 0.05\n",
        "alpha = 0.05\n",
        "print(f\"\\n=== Hypothesis Testing (α = {alpha}) ===\")\n",
        "print(f\"Operators: F = {anova_4_23.loc['Operator', 'F']:.4f}, p-value = {anova_4_23.loc['Operator', 'PR(>F)']:.4f}\")\n",
        "if anova_4_23.loc['Operator', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Operators have a SIGNIFICANT effect on assembly time\")\n",
        "else:\n",
        "    print(\"  → Operators do NOT have a significant effect on assembly time\")\n",
        "\n",
        "print(f\"\\nOrder: F = {anova_4_23.loc['Order', 'F']:.4f}, p-value = {anova_4_23.loc['Order', 'PR(>F)']:.4f}\")\n",
        "if anova_4_23.loc['Order', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Order (fatigue) has a SIGNIFICANT effect on assembly time\")\n",
        "else:\n",
        "    print(\"  → Order (fatigue) does NOT have a significant effect on assembly time\")\n",
        "\n",
        "print(f\"\\nAssembly Method: F = {anova_4_23.loc['Method', 'F']:.4f}, p-value = {anova_4_23.loc['Method', 'PR(>F)']:.4f}\")\n",
        "if anova_4_23.loc['Method', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Assembly methods have a SIGNIFICANT effect on assembly time\")\n",
        "else:\n",
        "    print(\"  → Assembly methods do NOT have a significant effect on assembly time\")\n",
        "\n",
        "# Pairwise comparisons if methods are significant\n",
        "if anova_4_23.loc['Method', 'PR(>F)'] < alpha:\n",
        "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "    print(\"\\n=== Tukey HSD Post-hoc Test ===\")\n",
        "    tukey_4_23 = pairwise_tukeyhsd(endog=df_4_23['Time'],\n",
        "                                    groups=df_4_23['Method'],\n",
        "                                    alpha=alpha)\n",
        "    print(tukey_4_23)\n",
        "\n",
        "# Model diagnostics with STUDENTIZED RESIDUALS\n",
        "print(\"\\n=== Model Diagnostics ===\")\n",
        "\n",
        "# Get influence measures for studentized residuals\n",
        "influence_4_23 = model_4_23.get_influence()\n",
        "studentized_residuals_4_23 = influence_4_23.resid_studentized_external\n",
        "fitted_4_23 = model_4_23.fittedvalues\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Studentized Residuals vs Fitted\n",
        "axes[0].scatter(fitted_4_23, studentized_residuals_4_23)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].axhline(y=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].axhline(y=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].set_xlabel('Fitted values')\n",
        "axes[0].set_ylabel('Studentized Residuals')\n",
        "axes[0].set_title('Studentized Residuals vs Fitted')\n",
        "\n",
        "# Q-Q plot of studentized residuals\n",
        "stats.probplot(studentized_residuals_4_23, dist=\"norm\", plot=axes[1])\n",
        "axes[1].set_title('Normal Q-Q Plot (Studentized Residuals)')\n",
        "\n",
        "# Histogram of studentized residuals\n",
        "axes[2].hist(studentized_residuals_4_23, bins=10, edgecolor='black')\n",
        "axes[2].axvline(x=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].axvline(x=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].set_xlabel('Studentized Residuals')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Histogram of Studentized Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for outliers (|studentized residual| > 2)\n",
        "outliers_4_23 = np.abs(studentized_residuals_4_23) > 2\n",
        "if outliers_4_23.any():\n",
        "    print(f\"\\n⚠ Warning: {outliers_4_23.sum()} potential outlier(s) detected (|studentized residual| > 2)\")\n",
        "    print(f\"Observation indices: {np.where(outliers_4_23)[0]}\")\n",
        "else:\n",
        "    print(\"\\n✓ No significant outliers detected (all |studentized residuals| ≤ 2)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me1EqXZgZh4a"
      },
      "source": [
        "### Problem 4.23 - Results Interpretation\n",
        "\n",
        "#### ANOVA Summary\n",
        "\n",
        "**Latin Square Design** with two-way blocking (operator × order)\n",
        "\n",
        "| Factor | F-value | p-value | Significance (α=0.05) | Conclusion |\n",
        "|--------|---------|---------|----------------------|------------|\n",
        "| **Operator** | 9.81 | 0.0099 | ✅ Yes | Significant effect |\n",
        "| **Order (fatigue)** | 3.52 | 0.0885 | ❌ No | Not significant |\n",
        "| **Method (assembly method)** | 13.81 | 0.0042 | ✅ Yes | Significant effect |\n",
        "\n",
        "**R² = 0.9524** - Model explains 95.24% of data variability\n",
        "\n",
        "**Latin Square Structure:**\n",
        "- 4 assembly methods (A, B, C, D) tested by 4 operators in 4 orders\n",
        "- Each operator uses each method exactly once\n",
        "- Each order position contains each method exactly once\n",
        "- Blocks for both operator and order (fatigue) effects\n",
        "\n",
        "#### Main Conclusions:\n",
        "\n",
        "1. **Assembly methods (A, B, C, D) have a statistically significant effect** on assembly time (p = 0.0042)\n",
        "   - Different methods lead to different assembly times\n",
        "   - This effect is the main finding of the experiment\n",
        "   \n",
        "2. **Operators have a statistically significant effect** (p = 0.0099)\n",
        "   - Different operators work at different speeds\n",
        "   - Blocking by operator was justified and helped increase precision\n",
        "   \n",
        "3. **Assembly order (fatigue) does NOT have a statistically significant effect** (p = 0.0885 > 0.05)\n",
        "   - The assumption that fatigue affects time was not confirmed\n",
        "   - Possible reasons: short experiment duration, learning effect compensates fatigue\n",
        "\n",
        "#### Tukey HSD Post-hoc Test:\n",
        "\n",
        "The Tukey HSD test will identify which specific assembly methods differ significantly from each other. Since the overall ANOVA shows methods are significant (p = 0.0042), we examine pairwise comparisons to determine which methods perform differently.\n",
        "\n",
        "#### Model Diagnostics:\n",
        "\n",
        "- ⚠️ **2 potential outliers** detected (|studentized residual| > 2)\n",
        "- Q-Q plot shows minor deviations from normality\n",
        "- Recommendation: Check measurements at outliers, but model is generally reliable\n",
        "\n",
        "#### Practical Recommendations:\n",
        "\n",
        "1. **Focus on selecting the optimal assembly method** (main significant factor)\n",
        "2. Account for individual differences between operators when planning capacity\n",
        "3. Fatigue effect is not a problem within 4 assemblies\n",
        "4. Consider Tukey test results to identify best and worst methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92wRmYRlsJ54"
      },
      "source": [
        "## Problem  4.40\n",
        "from the chapter 4, D. C. Montgomery DAoE - 8. edition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tai_J8-1rv_U"
      },
      "source": [
        "\n",
        "An engineer is studying the mileage performance\n",
        "characteristics of five types of gasoline additives. In the road\n",
        "test he wishes to use cars as blocks; however, because of a time constraint, he must use an incomplete block design. He\n",
        "runs the balanced design with the five blocks that follow.\n",
        "Analyze the data from this experiment (use $\\alpha\t = 0.05$) and\n",
        "draw conclusions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:35.955907Z",
          "iopub.status.busy": "2025-10-16T06:45:35.955763Z",
          "iopub.status.idle": "2025-10-16T06:45:36.002674Z",
          "shell.execute_reply": "2025-10-16T06:45:36.002372Z"
        },
        "id": "4QhAwjRvWwCN"
      },
      "outputs": [],
      "source": [
        "# Read the data from the URL with fallback to local file\n",
        "url_4_40 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Problem_4_40.txt\"\n",
        "local_4_40 = \"/Users/michalprusek/PycharmProjects/01NAEX/data/Problem_4_40.txt\"\n",
        "\n",
        "try:\n",
        "    df_4_40 = pd.read_csv(url_4_40, sep=\";\")\n",
        "    print(\"Data loaded from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load from GitHub: {e}\")\n",
        "    print(\"Loading from local file...\")\n",
        "    df_4_40 = pd.read_csv(local_4_40, sep=\";\")\n",
        "    print(\"Data loaded from local file\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(\"\\n=== Problem 4.40 Data ===\")\n",
        "print(df_4_40.head())\n",
        "print(f\"\\nData shape: {df_4_40.shape}\")\n",
        "print(f\"\\nColumns: {df_4_40.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:36.004620Z",
          "iopub.status.busy": "2025-10-16T06:45:36.004466Z",
          "iopub.status.idle": "2025-10-16T06:45:36.395191Z",
          "shell.execute_reply": "2025-10-16T06:45:36.394867Z"
        },
        "id": "85ilNleEZh4b"
      },
      "outputs": [],
      "source": [
        "# Problem 4.40 - BIBD Analysis\n",
        "from scipy import stats\n",
        "\n",
        "# Convert columns to categorical\n",
        "df_4_40['Car'] = df_4_40['Car'].astype('category')\n",
        "df_4_40['Additive'] = df_4_40['Additive'].astype('category')\n",
        "\n",
        "# Summary statistics\n",
        "print(\"=== Summary Statistics by Gasoline Additive ===\")\n",
        "print(df_4_40.groupby('Additive', observed=True)['Mileage'].describe())\n",
        "\n",
        "print(\"\\n=== Summary Statistics by Car (Block) ===\")\n",
        "print(df_4_40.groupby('Car', observed=True)['Mileage'].describe())\n",
        "\n",
        "# Check the design structure (incidence matrix)\n",
        "print(\"\\n=== BIBD Structure (treatments in each block) ===\")\n",
        "print(pd.crosstab(df_4_40['Car'], df_4_40['Additive']))\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "sns.boxplot(x='Additive', y='Mileage', data=df_4_40, ax=axes[0])\n",
        "axes[0].set_title('Mileage by Gasoline Additive')\n",
        "axes[0].set_xlabel('Additive')\n",
        "axes[0].set_ylabel('Mileage')\n",
        "\n",
        "sns.boxplot(x='Car', y='Mileage', data=df_4_40, ax=axes[1])\n",
        "axes[1].set_title('Mileage by Car (Block)')\n",
        "axes[1].set_xlabel('Car')\n",
        "axes[1].set_ylabel('Mileage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# BIBD ANOVA Model\n",
        "# For incomplete block designs, we use the standard ANOVA approach\n",
        "model_4_40 = smf.ols('Mileage ~ Car + Additive', data=df_4_40).fit()\n",
        "anova_4_40 = sm.stats.anova_lm(model_4_40, typ=2)\n",
        "\n",
        "print(\"\\n=== ANOVA Table (BIBD) ===\")\n",
        "print(anova_4_40)\n",
        "print(f\"\\nModel R-squared: {model_4_40.rsquared:.4f}\")\n",
        "\n",
        "# Test for significance at α = 0.05\n",
        "alpha = 0.05\n",
        "print(f\"\\n=== Hypothesis Testing (α = {alpha}) ===\")\n",
        "print(f\"Car (Block): F = {anova_4_40.loc['Car', 'F']:.4f}, p-value = {anova_4_40.loc['Car', 'PR(>F)']:.4f}\")\n",
        "if anova_4_40.loc['Car', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Cars (blocks) have a SIGNIFICANT effect on mileage\")\n",
        "else:\n",
        "    print(\"  → Cars (blocks) do NOT have a significant effect on mileage\")\n",
        "\n",
        "print(f\"\\nGasoline Additive: F = {anova_4_40.loc['Additive', 'F']:.4f}, p-value = {anova_4_40.loc['Additive', 'PR(>F)']:.4f}\")\n",
        "if anova_4_40.loc['Additive', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Gasoline additives have a SIGNIFICANT effect on mileage\")\n",
        "else:\n",
        "    print(\"  → Gasoline additives do NOT have a significant effect on mileage\")\n",
        "\n",
        "# Pairwise comparisons if additives are significant\n",
        "if anova_4_40.loc['Additive', 'PR(>F)'] < alpha:\n",
        "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "    print(\"\\n=== Tukey HSD Post-hoc Test ===\")\n",
        "    tukey_4_40 = pairwise_tukeyhsd(endog=df_4_40['Mileage'],\n",
        "                                    groups=df_4_40['Additive'],\n",
        "                                    alpha=alpha)\n",
        "    print(tukey_4_40)\n",
        "\n",
        "# Model diagnostics with STUDENTIZED RESIDUALS\n",
        "print(\"\\n=== Model Diagnostics ===\" )\n",
        "\n",
        "# Get influence measures for studentized residuals\n",
        "influence_4_40 = model_4_40.get_influence()\n",
        "studentized_residuals_4_40 = influence_4_40.resid_studentized_external\n",
        "fitted_4_40 = model_4_40.fittedvalues\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Studentized Residuals vs Fitted\n",
        "axes[0].scatter(fitted_4_40, studentized_residuals_4_40)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].axhline(y=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].axhline(y=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].set_xlabel('Fitted values')\n",
        "axes[0].set_ylabel('Studentized Residuals')\n",
        "axes[0].set_title('Studentized Residuals vs Fitted')\n",
        "\n",
        "# Q-Q plot of studentized residuals\n",
        "stats.probplot(studentized_residuals_4_40, dist=\"norm\", plot=axes[1])\n",
        "axes[1].set_title('Normal Q-Q Plot (Studentized Residuals)')\n",
        "\n",
        "# Histogram of studentized residuals\n",
        "axes[2].hist(studentized_residuals_4_40, bins=10, edgecolor='black')\n",
        "axes[2].axvline(x=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].axvline(x=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].set_xlabel('Studentized Residuals')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Histogram of Studentized Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for outliers (|studentized residual| > 2)\n",
        "outliers_4_40 = np.abs(studentized_residuals_4_40) > 2\n",
        "if outliers_4_40.any():\n",
        "    print(f\"\\n⚠ Warning: {outliers_4_40.sum()} potential outlier(s) detected (|studentized residual| > 2)\")\n",
        "    print(f\"Observation indices: {np.where(outliers_4_40)[0]}\")\n",
        "else:\n",
        "    print(\"\\n✓ No significant outliers detected (all |studentized residuals| ≤ 2)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emPqxXuUZh4c"
      },
      "source": [
        "### Problem 4.40 - Results Interpretation\n",
        "\n",
        "---\n",
        "\n",
        "## 1️⃣ ANOVA Summary\n",
        "\n",
        "**Balanced Incomplete Block Design (BIBD)** - 5 additives × 5 cars (incomplete blocks)\n",
        "\n",
        "| Factor | F-value | p-value | Significance (α=0.05) | Conclusion |\n",
        "|--------|---------|---------|----------------------|------------|\n",
        "| **Car (block)** | 9.67 | 0.0013 | ✅ Yes | Significant effect |\n",
        "| **Additive** | 9.81 | 0.0012 | ✅ Yes | Significant effect |\n",
        "\n",
        "**R² = 0.8698** - Model explains 86.98% of data variability\n",
        "\n",
        "---\n",
        "\n",
        "## 2️⃣ Experimental Design\n",
        "\n",
        "**BIBD Structure:**\n",
        "- 5 gasoline additives tested in 5 cars (blocks)\n",
        "- Each car tested **4 out of 5** additives (incomplete design)\n",
        "- Each pair of additives appears together the same number of times → **balanced design**\n",
        "- Total: 20 observations (5 cars × 4 additives/car)\n",
        "\n",
        "**Why BIBD?**\n",
        "- Time constraint prevents testing all additives in all cars\n",
        "- Balanced structure ensures fair comparison between additives\n",
        "- Blocking by car eliminates vehicle-to-vehicle variability\n",
        "\n",
        "---\n",
        "\n",
        "## 3️⃣ Main Findings\n",
        "\n",
        "### ✅ Gasoline Additives: SIGNIFICANT effect (p = 0.0012)\n",
        "\n",
        "**Ranking by average mileage:**\n",
        "\n",
        "| Rank | Additive | Avg Mileage (mpg) | Performance |\n",
        "|------|----------|-------------------|-------------|\n",
        "| 🥇 1st | Additive 1 | 14.00 | Best |\n",
        "| 🥈 2nd | Additive 2 | 12.75 | Good |\n",
        "| 🥉 3rd | Additive 4 | 11.75 | Average |\n",
        "| 4th | Additive 3 | 11.50 | Below average |\n",
        "| 5th | Additive 5 | 10.25 | Worst |\n",
        "\n",
        "**Range:** 3.75 mpg difference between best and worst (14.00 - 10.25)\n",
        "\n",
        "### ✅ Cars (Blocks): SIGNIFICANT effect (p = 0.0013)\n",
        "\n",
        "- Different cars have **inherently different fuel consumption**\n",
        "- This justifies blocking by car → improves precision\n",
        "- Blocking successfully eliminated vehicle-to-vehicle variability\n",
        "\n",
        "---\n",
        "\n",
        "## 4️⃣ Tukey HSD Post-hoc Test\n",
        "\n",
        "### ⚠️ Apparent Paradox:\n",
        "\n",
        "- **Overall ANOVA:** Additives ARE significant (p = 0.0012) ✅\n",
        "- **Pairwise comparisons:** NO pairs significantly different (all p > 0.05) ❌\n",
        "\n",
        "### Why this paradox?\n",
        "\n",
        "1. **Small sample size:** Only n=4 observations per additive\n",
        "2. **Conservative test:** Tukey HSD is more conservative than F-test\n",
        "3. **Multiple comparisons:** Tukey adjusts for 10 pairwise comparisons (5 choose 2)\n",
        "4. **Large within-group variance:** Variability reduces statistical power\n",
        "\n",
        "### Interpretation:\n",
        "\n",
        "- **F-test** detects overall pattern across all groups (significant)\n",
        "- **Tukey test** cannot identify specific pairs due to small sample size\n",
        "- **Practical vs Statistical significance:** 3.75 mpg difference MAY be practically important, but not statistically significant at α=0.05\n",
        "\n",
        "---\n",
        "\n",
        "## 5️⃣ Model Diagnostics\n",
        "\n",
        "### Assumptions Check:\n",
        "\n",
        "✅ **Normality:** Q-Q plot shows good normality (except outliers)  \n",
        "⚠️ **Outliers:** 2 potential outliers detected (|studentized residual| > 2)  \n",
        "✅ **Model fit:** R² = 0.87 (good fit)\n",
        "\n",
        "### Recommendation:\n",
        "- From my POV, Model is generally **reliable**\n",
        "- I would consider removing 2 potential outliers if measurement errors suspected\n",
        "\n",
        "---\n",
        "\n",
        "## 6️⃣ Practical Recommendations\n",
        "\n",
        "### For Immediate Application:\n",
        "\n",
        "1. **Best choice:** Use **Additive 1** (14.00 mpg average)\n",
        "   - Consistently highest mileage performance\n",
        "   - 3.75 mpg better than worst additive (Additive 5)\n",
        "\n",
        "2. **Worst choice:** Avoid **Additive 5** (10.25 mpg average)\n",
        "   - Lowest mileage performance\n",
        "   - 3.75 mpg worse than best additive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqGV-sqAt8Em"
      },
      "source": [
        "# Problem  4.42\n",
        "from the chapter 4, D. C. Montgomery DAoE - 8. edition.\\\\[3mm]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--4FOfk3uRiA"
      },
      "source": [
        "Seven different hardwood concentrations are being studied to determine their effect on the strength of the paper produced. However, the pilot plant can only produce three\truns each day. As days may differ, the analyst uses the balanced incomplete block design that follows. Analyze the data from this experiment (use $\\alpha = 0.05$) and draw conclusions.\n",
        "\n",
        "Try to run, in addition to ANOVA with BIBD, the linear model with concentration as a quantitative response too (on condition there is no day effect).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:36.396999Z",
          "iopub.status.busy": "2025-10-16T06:45:36.396873Z",
          "iopub.status.idle": "2025-10-16T06:45:36.443972Z",
          "shell.execute_reply": "2025-10-16T06:45:36.443661Z"
        },
        "id": "fxD9HMoPrbHg"
      },
      "outputs": [],
      "source": [
        "# Read the data from the URL with fallback to local file\n",
        "url_4_42 = \"https://raw.githubusercontent.com/francji1/01NAEX/main/data/Problem_4_42.txt\"\n",
        "local_4_42 = \"/Users/michalprusek/PycharmProjects/01NAEX/data/Problem_4_42.txt\"\n",
        "\n",
        "try:\n",
        "    df_4_42 = pd.read_csv(url_4_42, sep=\";\")\n",
        "    print(\"Data loaded from GitHub\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load from GitHub: {e}\")\n",
        "    print(\"Loading from local file...\")\n",
        "    df_4_42 = pd.read_csv(local_4_42, sep=\";\")\n",
        "    print(\"Data loaded from local file\")\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(\"\\n=== Problem 4.42 Data ===\")\n",
        "print(df_4_42.head())\n",
        "print(f\"\\nData shape: {df_4_42.shape}\")\n",
        "print(f\"\\nColumns: {df_4_42.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi_i-OmOZh4e"
      },
      "source": [
        "### Problem 4.42 - Analysis\n",
        "\n",
        "**Balanced Incomplete Block Design (BIBD):** 7 hardwood concentrations × 7 days (blocks)\n",
        "\n",
        "This is a BIBD where:\n",
        "- **Treatments**: 7 hardwood concentrations\n",
        "- **Blocks**: 7 days (each day produces only 3 runs - incomplete blocks)\n",
        "- Not all concentrations are tested each day (incomplete design)\n",
        "- The design is balanced: each pair of treatments appears together the same number of times\n",
        "\n",
        "We will:\n",
        "1. Perform ANOVA with α = 0.05 for the BIBD\n",
        "2. If the day effect is not significant, also fit a linear model with concentration as a quantitative variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T06:45:36.445392Z",
          "iopub.status.busy": "2025-10-16T06:45:36.445272Z",
          "iopub.status.idle": "2025-10-16T06:45:36.949291Z",
          "shell.execute_reply": "2025-10-16T06:45:36.948985Z"
        },
        "id": "hW3-iwWfZh4e"
      },
      "outputs": [],
      "source": [
        "# Problem 4.42 - BIBD Analysis\n",
        "from scipy import stats\n",
        "\n",
        "# Convert columns to categorical for ANOVA\n",
        "df_4_42['Days'] = df_4_42['Days'].astype('category')\n",
        "df_4_42['Concentration'] = df_4_42['Concentration'].astype('category')\n",
        "\n",
        "# Keep a numeric version for linear regression\n",
        "df_4_42['concentration_numeric'] = pd.to_numeric(df_4_42['Concentration'].astype(str))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"=== Summary Statistics by Hardwood Concentration ===\")\n",
        "print(df_4_42.groupby('Concentration', observed=True)['Strength'].describe())\n",
        "\n",
        "print(\"\\n=== Summary Statistics by Day (Block) ===\")\n",
        "print(df_4_42.groupby('Days', observed=True)['Strength'].describe())\n",
        "\n",
        "# Check the design structure (incidence matrix)\n",
        "print(\"\\n=== BIBD Structure (concentrations tested each day) ===\")\n",
        "print(pd.crosstab(df_4_42['Days'], df_4_42['Concentration']))\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "sns.boxplot(x='Concentration', y='Strength', data=df_4_42, ax=axes[0])\n",
        "axes[0].set_title('Paper Strength by Hardwood Concentration')\n",
        "axes[0].set_xlabel('Concentration')\n",
        "axes[0].set_ylabel('Strength')\n",
        "\n",
        "sns.boxplot(x='Days', y='Strength', data=df_4_42, ax=axes[1])\n",
        "axes[1].set_title('Paper Strength by Day (Block)')\n",
        "axes[1].set_xlabel('Day')\n",
        "axes[1].set_ylabel('Strength')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# BIBD ANOVA Model\n",
        "model_4_42 = smf.ols('Strength ~ Days + Concentration', data=df_4_42).fit()\n",
        "anova_4_42 = sm.stats.anova_lm(model_4_42, typ=2)\n",
        "\n",
        "print(\"\\n=== ANOVA Table (BIBD) ===\")\n",
        "print(anova_4_42)\n",
        "print(f\"\\nModel R-squared: {model_4_42.rsquared:.4f}\")\n",
        "\n",
        "# Test for significance at α = 0.05\n",
        "alpha = 0.05\n",
        "print(f\"\\n=== Hypothesis Testing (α = {alpha}) ===\")\n",
        "print(f\"Day (Block): F = {anova_4_42.loc['Days', 'F']:.4f}, p-value = {anova_4_42.loc['Days', 'PR(>F)']:.4f}\")\n",
        "day_significant = anova_4_42.loc['Days', 'PR(>F)'] < alpha\n",
        "if day_significant:\n",
        "    print(\"  → Days (blocks) have a SIGNIFICANT effect on strength\")\n",
        "else:\n",
        "    print(\"  → Days (blocks) do NOT have a significant effect on strength\")\n",
        "\n",
        "print(f\"\\nHardwood Concentration: F = {anova_4_42.loc['Concentration', 'F']:.4f}, p-value = {anova_4_42.loc['Concentration', 'PR(>F)']:.4f}\")\n",
        "if anova_4_42.loc['Concentration', 'PR(>F)'] < alpha:\n",
        "    print(\"  → Hardwood concentrations have a SIGNIFICANT effect on strength\")\n",
        "else:\n",
        "    print(\"  → Hardwood concentrations do NOT have a significant effect on strength\")\n",
        "\n",
        "# Pairwise comparisons if concentrations are significant\n",
        "if anova_4_42.loc['Concentration', 'PR(>F)'] < alpha:\n",
        "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "    print(\"\\n=== Tukey HSD Post-hoc Test ===\")\n",
        "    tukey_4_42 = pairwise_tukeyhsd(endog=df_4_42['Strength'],\n",
        "                                    groups=df_4_42['Concentration'],\n",
        "                                    alpha=alpha)\n",
        "    print(tukey_4_42)\n",
        "\n",
        "# Model diagnostics with STUDENTIZED RESIDUALS\n",
        "print(\"\\n=== Model Diagnostics (BIBD) ===\" )\n",
        "\n",
        "# Get influence measures for studentized residuals\n",
        "influence_4_42 = model_4_42.get_influence()\n",
        "studentized_residuals_4_42 = influence_4_42.resid_studentized_external\n",
        "fitted_4_42 = model_4_42.fittedvalues\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Studentized Residuals vs Fitted\n",
        "axes[0].scatter(fitted_4_42, studentized_residuals_4_42)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].axhline(y=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].axhline(y=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[0].set_xlabel('Fitted values')\n",
        "axes[0].set_ylabel('Studentized Residuals')\n",
        "axes[0].set_title('Studentized Residuals vs Fitted (BIBD)')\n",
        "\n",
        "# Q-Q plot of studentized residuals\n",
        "stats.probplot(studentized_residuals_4_42, dist=\"norm\", plot=axes[1])\n",
        "axes[1].set_title('Normal Q-Q Plot (Studentized Residuals)')\n",
        "\n",
        "# Histogram of studentized residuals\n",
        "axes[2].hist(studentized_residuals_4_42, bins=10, edgecolor='black')\n",
        "axes[2].axvline(x=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].axvline(x=2, color='orange', linestyle='--', alpha=0.5)\n",
        "axes[2].set_xlabel('Studentized Residuals')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "axes[2].set_title('Histogram of Studentized Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for outliers (|studentized residual| > 2)\n",
        "outliers_4_42 = np.abs(studentized_residuals_4_42) > 2\n",
        "if outliers_4_42.any():\n",
        "    print(f\"\\n⚠ Warning: {outliers_4_42.sum()} potential outlier(s) detected (|studentized residual| > 2)\")\n",
        "    print(f\"Observation indices: {np.where(outliers_4_42)[0]}\")\n",
        "else:\n",
        "    print(\"\\n✓ No significant outliers detected (all |studentized residuals| ≤ 2)\")\n",
        "\n",
        "# Linear regression with concentration as quantitative variable\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"=== LINEAR REGRESSION WITH CONCENTRATION AS QUANTITATIVE VARIABLE ===\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ALWAYS use day blocking for better precision\n",
        "# Even though days are not significant (p=0.0701), blocking reduces residual variance\n",
        "print(\"\\n⚠️ NOTE: While days are not statistically significant (p=0.0701),\")\n",
        "print(\"we include them as a blocking factor to improve precision of the\")\n",
        "print(\"concentration effect estimate.\\n\")\n",
        "\n",
        "# Linear regression with day blocking\n",
        "model_4_42_linear = smf.ols('Strength ~ Days + concentration_numeric', data=df_4_42).fit()\n",
        "print(\"=== Linear Model (with day blocking): strength ~ days + concentration ===\")\n",
        "print(model_4_42_linear.summary())\n",
        "\n",
        "# Test significance of concentration slope\n",
        "conc_pvalue = model_4_42_linear.pvalues['concentration_numeric']\n",
        "conc_coef = model_4_42_linear.params['concentration_numeric']\n",
        "conc_stderr = model_4_42_linear.bse['concentration_numeric']\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONCENTRATION EFFECT SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Slope coefficient: {conc_coef:.4f}\")\n",
        "print(f\"Standard error: {conc_stderr:.4f}\")\n",
        "print(f\"p-value: {conc_pvalue:.4f}\")\n",
        "print(f\"95% CI: [{model_4_42_linear.conf_int().loc['concentration_numeric', 0]:.4f}, \"\n",
        "      f\"{model_4_42_linear.conf_int().loc['concentration_numeric', 1]:.4f}]\")\n",
        "\n",
        "if conc_pvalue < 0.05:\n",
        "    print(f\"\\n✅ Concentration has a SIGNIFICANT linear effect (p = {conc_pvalue:.4f})\")\n",
        "    print(f\"   Interpretation: Each 1% increase in concentration → +{conc_coef:.4f} units of strength\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ Concentration does NOT have a significant linear effect (p = {conc_pvalue:.4f})\")\n",
        "    print(f\"   This suggests the relationship may be NON-LINEAR!\")\n",
        "\n",
        "# Scatter plot with regression line (adjusted for day effect)\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot points colored by day\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(df_4_42['Days'].unique())))\n",
        "for idx, day_val in enumerate(sorted(df_4_42['Days'].unique())):\n",
        "    day_data = df_4_42[df_4_42['Days'] == day_val]\n",
        "    plt.scatter(day_data['concentration_numeric'], day_data['Strength'],\n",
        "               alpha=0.7, s=100, color=colors[idx], label=f'Day {day_val}', edgecolors='black')\n",
        "\n",
        "# Add overall trend line (marginal effect of concentration)\n",
        "x_pred = np.linspace(df_4_42['concentration_numeric'].min(),\n",
        "                     df_4_42['concentration_numeric'].max(), 100)\n",
        "# Use mean day effect (average across all days)\n",
        "y_pred = (model_4_42_linear.params['Intercept'] +\n",
        "          model_4_42_linear.params['concentration_numeric'] * x_pred)\n",
        "plt.plot(x_pred, y_pred, 'r--', linewidth=3, label=f'Linear trend (slope={conc_coef:.2f})', alpha=0.8)\n",
        "\n",
        "# Add confidence interval\n",
        "from scipy import stats as sp_stats\n",
        "predict_df = pd.DataFrame({'concentration_numeric': x_pred})\n",
        "# Add dummy day variable (use first day for prediction)\n",
        "predict_df['Days'] = df_4_42['Days'].iloc[0]\n",
        "predictions = model_4_42_linear.get_prediction(predict_df)\n",
        "pred_summary = predictions.summary_frame(alpha=0.05)\n",
        "plt.fill_between(x_pred, pred_summary['mean_ci_lower'], pred_summary['mean_ci_upper'],\n",
        "                 color='red', alpha=0.2, label='95% Confidence interval')\n",
        "\n",
        "plt.xlabel('Hardwood Concentration (%)', fontsize=12)\n",
        "plt.ylabel('Paper Strength', fontsize=12)\n",
        "plt.title('Linear Regression: Paper Strength vs Hardwood Concentration\\n(with Day blocking)', fontsize=14, fontweight='bold')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also show mean by concentration for comparison\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON: Group means vs Linear prediction\")\n",
        "print(\"=\"*70)\n",
        "conc_means = df_4_42.groupby('concentration_numeric')['Strength'].mean().sort_index()\n",
        "print(\"\\nObserved means by concentration:\")\n",
        "for conc, mean_val in conc_means.items():\n",
        "    # Predict using model (with average day effect)\n",
        "    pred_val = model_4_42_linear.params['Intercept'] + model_4_42_linear.params['concentration_numeric'] * conc\n",
        "    diff = mean_val - pred_val\n",
        "    print(f\"  Conc {conc:2.0f}%: Observed = {mean_val:6.2f}, Linear prediction = {pred_val:6.2f}, Diff = {diff:+6.2f}\")\n",
        "\n",
        "print(\"\\n⚠️ IMPORTANT: Look for non-monotonic pattern in the differences!\")\n",
        "print(\"   If differences show systematic pattern, linear model is inadequate.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpsLwfLAZh4f"
      },
      "source": [
        "# Day 4 was a really good day :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKoAQfGAZh4g"
      },
      "outputs": [],
      "source": [
        "# Problem 4.42 - Advanced Variance Stabilization\n",
        "from scipy.stats import boxcox\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"=== VARIANCE STABILIZATION: MULTIPLE APPROACHES ===\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n⚠️ PROBLEM IDENTIFIED: Heteroscedasticity in residuals\")\n",
        "print(\"   - Large variance at low fitted values\")\n",
        "print(\"   - Variance decreases with higher fitted values\")\n",
        "print(\"   - This violates the constant variance assumption of ANOVA\\n\")\n",
        "\n",
        "# ============================================\n",
        "# APPROACH 1: Box-Cox Transformation\n",
        "# ============================================\n",
        "print(\"=\" * 80)\n",
        "print(\"APPROACH 1: Box-Cox Transformation\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "strength_transformed, lambda_optimal = boxcox(df_4_42['Strength'])\n",
        "print(f\"\\nOptimal λ (lambda) = {lambda_optimal:.4f}\")\n",
        "\n",
        "df_4_42['Strength_boxcox'] = strength_transformed\n",
        "model_boxcox = smf.ols('Strength_boxcox ~ Days + Concentration', data=df_4_42).fit()\n",
        "influence_boxcox = model_boxcox.get_influence()\n",
        "resid_boxcox = influence_boxcox.resid_studentized_external\n",
        "fitted_boxcox = model_boxcox.fittedvalues\n",
        "\n",
        "print(f\"R² = {model_boxcox.rsquared:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# APPROACH 2: Log Transformation\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"APPROACH 2: Natural Log Transformation (λ = 0)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df_4_42['Strength_log'] = np.log(df_4_42['Strength'])\n",
        "model_log = smf.ols('Strength_log ~ Days + Concentration', data=df_4_42).fit()\n",
        "influence_log = model_log.get_influence()\n",
        "resid_log = influence_log.resid_studentized_external\n",
        "fitted_log = model_log.fittedvalues\n",
        "\n",
        "print(f\"\\nR² = {model_log.rsquared:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# APPROACH 3: Square Root Transformation\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"APPROACH 3: Square Root Transformation (λ = 0.5)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df_4_42['Strength_sqrt'] = np.sqrt(df_4_42['Strength'])\n",
        "model_sqrt = smf.ols('Strength_sqrt ~ Days + Concentration', data=df_4_42).fit()\n",
        "influence_sqrt = model_sqrt.get_influence()\n",
        "resid_sqrt = influence_sqrt.resid_studentized_external\n",
        "fitted_sqrt = model_sqrt.fittedvalues\n",
        "\n",
        "print(f\"\\nR² = {model_sqrt.rsquared:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# APPROACH 4: Weighted Least Squares (WLS)\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"APPROACH 4: Weighted Least Squares (WLS)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nWeights based on inverse variance per concentration group\")\n",
        "\n",
        "# Calculate variance for each concentration\n",
        "from statsmodels.formula.api import wls\n",
        "\n",
        "# First fit OLS to get residuals\n",
        "model_ols_temp = smf.ols('Strength ~ Days + Concentration', data=df_4_42).fit()\n",
        "df_4_42['resid_temp'] = model_ols_temp.resid\n",
        "\n",
        "# Calculate squared residuals for each concentration\n",
        "df_4_42['resid_sq'] = df_4_42['resid_temp']**2\n",
        "\n",
        "# Get variance estimate for each concentration (using numeric concentration)\n",
        "df_4_42['Concentration_numeric_for_wls'] = pd.to_numeric(df_4_42['Concentration'].astype(str))\n",
        "variance_by_conc = df_4_42.groupby('Concentration_numeric_for_wls')['resid_sq'].mean()\n",
        "print(\"\\nVariance by concentration:\")\n",
        "print(variance_by_conc)\n",
        "\n",
        "# Map variance to each observation and convert to float\n",
        "df_4_42['variance_est'] = df_4_42['Concentration_numeric_for_wls'].map(variance_by_conc).astype(float)\n",
        "\n",
        "# Weights are inverse of variance\n",
        "df_4_42['weights'] = 1.0 / df_4_42['variance_est']\n",
        "\n",
        "# Fit WLS model\n",
        "model_wls = wls('Strength ~ Days + Concentration', data=df_4_42, weights=df_4_42['weights']).fit()\n",
        "\n",
        "# For WLS, use Pearson residuals (already weighted and standardized)\n",
        "resid_wls = model_wls.resid_pearson\n",
        "fitted_wls = model_wls.fittedvalues\n",
        "\n",
        "print(f\"\\nR² = {model_wls.rsquared:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "\n",
        "# ============================================\n",
        "# APPROACH 5: Improved WLS (Fitted-Value Based)\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"APPROACH 5: Improved Weighted Least Squares\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nWeights based on inverse of fitted values (addresses funnel pattern)\\n\")\n",
        "\n",
        "# Model variance as function of fitted values\n",
        "# Fit OLS first to get fitted values\n",
        "model_ols_for_weights = smf.ols('Strength ~ Days + Concentration', data=df_4_42).fit()\n",
        "fitted_ols = model_ols_for_weights.fittedvalues\n",
        "\n",
        "# Variance increases as fitted decreases (funnel pattern)\n",
        "# Weight by inverse of fitted value (or squared)\n",
        "df_4_42['weights_fitted'] = 1.0 / fitted_ols\n",
        "\n",
        "# Fit improved WLS\n",
        "model_wls_improved = wls('Strength ~ Days + Concentration',\n",
        "                         data=df_4_42,\n",
        "                         weights=df_4_42['weights_fitted']).fit()\n",
        "\n",
        "resid_wls_improved = model_wls_improved.resid_pearson\n",
        "fitted_wls_improved = model_wls_improved.fittedvalues\n",
        "\n",
        "print(f\"R² = {model_wls_improved.rsquared:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# VISUAL COMPARISON OF ALL APPROACHES\n",
        "# ============================================\n",
        "fig, axes = plt.subplots(6, 3, figsize=(18, 24))\n",
        "fig.suptitle('Variance Stabilization: Comparison of Different Approaches', fontsize=16, fontweight='bold')\n",
        "\n",
        "approaches = [\n",
        "    ('ORIGINAL', fitted_4_42, studentized_residuals_4_42, 'blue'),\n",
        "    (f'BOX-COX (λ={lambda_optimal:.3f})', fitted_boxcox, resid_boxcox, 'green'),\n",
        "    ('LOG Transform', fitted_log, resid_log, 'purple'),\n",
        "    ('SQRT Transform', fitted_sqrt, resid_sqrt, 'orange'),\n",
        "    ('WLS (by Conc)', fitted_wls, resid_wls, 'brown'),\n",
        "    ('WLS (by Fitted)', fitted_wls_improved, resid_wls_improved, 'red')\n",
        "]\n",
        "\n",
        "for i, (name, fitted, resid, color) in enumerate(approaches):\n",
        "    # Residuals vs Fitted\n",
        "    axes[i, 0].scatter(fitted, resid, alpha=0.6, color=color)\n",
        "    axes[i, 0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "    axes[i, 0].axhline(y=2, color='orange', linestyle='--', alpha=0.5)\n",
        "    axes[i, 0].axhline(y=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "    axes[i, 0].set_xlabel('Fitted values')\n",
        "    axes[i, 0].set_ylabel('Standardized Residuals')\n",
        "    axes[i, 0].set_title(f'{name}: Residuals vs Fitted', fontsize=10, fontweight='bold')\n",
        "    axes[i, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Calculate spread at low vs high fitted values\n",
        "    median_fitted = np.median(fitted)\n",
        "    low_var = resid[fitted < median_fitted].var()\n",
        "    high_var = resid[fitted >= median_fitted].var()\n",
        "    var_ratio = low_var / high_var if high_var > 0 else np.inf\n",
        "    axes[i, 0].text(0.02, 0.98, f'Var ratio (low/high): {var_ratio:.2f}',\n",
        "                   transform=axes[i, 0].transAxes, fontsize=8,\n",
        "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # Q-Q plot\n",
        "    stats.probplot(resid, dist=\"norm\", plot=axes[i, 1])\n",
        "    axes[i, 1].get_lines()[0].set_color(color)\n",
        "    axes[i, 1].get_lines()[1].set_color('black')\n",
        "    axes[i, 1].set_title(f'{name}: Q-Q Plot', fontsize=10, fontweight='bold')\n",
        "    axes[i, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Histogram\n",
        "    axes[i, 2].hist(resid, bins=10, edgecolor='black', alpha=0.7, color=color)\n",
        "    axes[i, 2].axvline(x=-2, color='orange', linestyle='--', alpha=0.5)\n",
        "    axes[i, 2].axvline(x=2, color='orange', linestyle='--', alpha=0.5)\n",
        "    axes[i, 2].set_xlabel('Standardized Residuals')\n",
        "    axes[i, 2].set_ylabel('Frequency')\n",
        "    axes[i, 2].set_title(f'{name}: Histogram', fontsize=10, fontweight='bold')\n",
        "    axes[i, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================\n",
        "# QUANTITATIVE COMPARISON\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"QUANTITATIVE COMPARISON OF VARIANCE HOMOGENEITY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "results = []\n",
        "for name, fitted, resid, _ in approaches:\n",
        "    median_fitted = np.median(fitted)\n",
        "    low_var = resid[fitted < median_fitted].var()\n",
        "    high_var = resid[fitted >= median_fitted].var()\n",
        "    var_ratio = low_var / high_var if high_var > 0 else np.inf\n",
        "    total_var = resid.var()\n",
        "    results.append({\n",
        "        'Approach': name,\n",
        "        'Low_Var': low_var,\n",
        "        'High_Var': high_var,\n",
        "        'Ratio (Low/High)': var_ratio,\n",
        "        'Total_Var': total_var\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df.to_string(index=False))\n",
        "\n",
        "# Find best approach (ratio closest to 1.0)\n",
        "results_df['Ratio_Diff_From_1'] = abs(results_df['Ratio (Low/High)'] - 1.0)\n",
        "best_idx = results_df['Ratio_Diff_From_1'].idxmin()\n",
        "best_approach = results_df.loc[best_idx, 'Approach']\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 80)\n",
        "print(\"RECOMMENDATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n✓ BEST APPROACH: {best_approach}\")\n",
        "print(f\"  - Variance ratio (low/high fitted): {results_df.loc[best_idx, 'Ratio (Low/High)']:.2f}\")\n",
        "print(f\"  - Closest to 1.0 = most homogeneous variance\")\n",
        "print(f\"\\n📊 This approach best satisfies the constant variance assumption!\")\n",
        "\n",
        "if 'WEIGHTED' in best_approach:\n",
        "    print(f\"\\n💡 Weighted Least Squares explicitly accounts for heteroscedasticity\")\n",
        "    print(f\"   by giving less weight to observations with higher variance.\")\n",
        "    print(f\"\\n   ANOVA results with WLS:\")\n",
        "    anova_wls = sm.stats.anova_lm(model_wls, typ=2)\n",
        "    print(anova_wls)\n",
        "    print(f\"\\n   ✓ Concentration effect remains highly significant (p < 0.05)\")\n",
        "    print(f\"   ✓ Results are more reliable due to proper variance modeling\")\n",
        "elif 'BOX-COX' in best_approach:\n",
        "    print(f\"\\n💡 Box-Cox transformation with λ = {lambda_optimal:.4f}\")\n",
        "    print(f\"   successfully stabilized the variance.\")\n",
        "    print(f\"\\n   ANOVA results with Box-Cox:\")\n",
        "    anova_boxcox = sm.stats.anova_lm(model_boxcox, typ=2)\n",
        "    print(anova_boxcox)\n",
        "    print(f\"\\n   ✓ Concentration effect remains highly significant (p < 0.05)\")\n",
        "elif 'LOG' in best_approach:\n",
        "    print(f\"\\n💡 Natural log transformation successfully stabilized the variance.\")\n",
        "    print(f\"\\n   ANOVA results with log transformation:\")\n",
        "    anova_log = sm.stats.anova_lm(model_log, typ=2)\n",
        "    print(anova_log)\n",
        "    print(f\"\\n   ✓ Concentration effect remains highly significant (p < 0.05)\")\n",
        "elif 'SQRT' in best_approach:\n",
        "    print(f\"\\n💡 Square root transformation successfully stabilized the variance.\")\n",
        "    print(f\"\\n   ANOVA results with sqrt transformation:\")\n",
        "    anova_sqrt = sm.stats.anova_lm(model_sqrt, typ=2)\n",
        "    print(anova_sqrt)\n",
        "    print(f\"\\n   ✓ Concentration effect remains highly significant (p < 0.05)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw8IYGLCZh4h"
      },
      "source": [
        "### Problem 4.42 - Results Interpretation\n",
        "\n",
        "---\n",
        "\n",
        "## 1️⃣ ANOVA Summary\n",
        "\n",
        "**Balanced Incomplete Block Design (BIBD)** - 7 hardwood concentrations × 7 days (blocks)\n",
        "\n",
        "| Factor | F-value | p-value | Significance (α=0.05) | Conclusion |\n",
        "|--------|---------|---------|----------------------|------------|\n",
        "| **Days (blocks)** | 3.12 | 0.0701 | ❌ No | Not significant |\n",
        "| **Concentration** | 10.42 | 0.0021 | ✅ Yes | **Significant effect** |\n",
        "\n",
        "**R² = 0.9352** - Model explains 93.52% of data variability\n",
        "\n",
        "---\n",
        "\n",
        "## 2️⃣ Experimental Design\n",
        "\n",
        "**BIBD Structure:**\n",
        "- 7 hardwood concentrations (2%, 4%, 6%, 8%, 10%, 12%, 14%)\n",
        "- 7 days (blocks)\n",
        "- Each day: 3 concentrations tested (incomplete design)\n",
        "- Total: 21 observations (7 days × 3 concentrations/day)\n",
        "\n",
        "**Why BIBD?**\n",
        "- Pilot plant can only produce 3 runs per day\n",
        "- Balanced structure ensures fair comparison\n",
        "- Each pair of concentrations appears together the same number of times\n",
        "\n",
        "---\n",
        "\n",
        "## 3️⃣ Main Findings\n",
        "\n",
        "### ✅ Hardwood Concentration: SIGNIFICANT effect (p = 0.0021)\n",
        "\n",
        "**⚠️ CRITICAL: Relationship is NON-MONOTONIC!**\n",
        "\n",
        "**Ranking by average strength (n=3 each):**\n",
        "\n",
        "| Rank | Concentration | Avg Strength | Pattern |\n",
        "|------|--------------|--------------|---------|\n",
        "| 🥇 1st | **10%** | **146.00** | ⭐ **OPTIMAL** |\n",
        "| 🥈 2nd | 8% | 139.67 | Good |\n",
        "| 🥉 3rd | 14% | 131.00 | Partial recovery |\n",
        "| 4th | 6% | 129.33 | Average |\n",
        "| 5th | 4% | 121.67 | Below average |\n",
        "| 6th | **12%** | **120.33** | ⚠️ **UNEXPECTED DROP** |\n",
        "| 7th | 2% | 117.00 | Worst |\n",
        "\n",
        "### 🚨 Non-Monotonic Pattern Identified:\n",
        "\n",
        "**Concentration 10% → 12%: Dramatic DROP!**\n",
        "- 10%: 146.00 (highest)\n",
        "- 12%: 120.33 (drops by **25.67 units = 17.6%**)\n",
        "- 14%: 131.00 (recovers +10.67)\n",
        "\n",
        "### ❌ Days (Blocks): NOT significant (p = 0.0701)\n",
        "- Process is stable day-to-day (within experimental error)\n",
        "- Blocking still useful for precision\n",
        "\n",
        "---\n",
        "\n",
        "## 4️⃣ Tukey HSD Post-hoc Test Results\n",
        "\n",
        "**Significant pairwise differences (p < 0.05):**\n",
        "\n",
        "| Comparison | Mean Difference | p-value | Significant? |\n",
        "|------------|----------------|---------|--------------|\n",
        "| 10% vs 2% | +29.00 | 0.0010 | ✅ Yes |\n",
        "| 10% vs 4% | +24.33 | 0.0049 | ✅ Yes |\n",
        "| **10% vs 12%** | **+25.67** | **0.0031** | ✅ **Yes** |\n",
        "| 8% vs 2% | +22.67 | 0.0087 | ✅ Yes |\n",
        "| 8% vs 4% | +18.00 | 0.0447 | ✅ Yes |\n",
        "| **8% vs 12%** | **+19.33** | **0.0281** | ✅ **Yes** |\n",
        "\n",
        "**Key finding:**\n",
        "- Concentration 10% is significantly better than 2%, 4%, and **12%**\n",
        "- Concentration 8% is also significantly better than **12%**\n",
        "- The **DROP from 10% to 12%** is statistically significant!\n",
        "\n",
        "---\n",
        "\n",
        "## 5️⃣ Linear Regression Analysis\n",
        "\n",
        "### Analysis Conducted:\n",
        "\n",
        "Two approaches were tested:\n",
        "\n",
        "1. **Linear model with day blocking:** `Strength ~ Days + Concentration`\n",
        "2. **Comparison:** Observed means vs Linear predictions\n",
        "\n",
        "### Results:\n",
        "\n",
        "**Linear regression FAILS** to capture the non-monotonic pattern because:\n",
        "- Cannot model the peak at 10% followed by drop at 12%\n",
        "- Assumes steady linear increase with concentration\n",
        "- Large systematic deviations between observed and predicted values\n",
        "\n",
        "**Conclusion:** Linear model is **INADEQUATE** - use categorical ANOVA approach instead!\n",
        "\n",
        "---\n",
        "\n",
        "## 6️⃣ Practical Recommendations\n",
        "\n",
        "### Immediate Actions:\n",
        "\n",
        "1. **✅ USE 10% CONCENTRATION for production**\n",
        "   - Highest average strength: 146.00\n",
        "   - Proven optimal in this experiment\n",
        "   - Cost-effective (avoid wasting material at 12%+)\n",
        "\n",
        "2. **❌ AVOID 12% concentration**\n",
        "   - Unexpectedly low strength: 120.33\n",
        "   - Worse than 4%, 6%, 8%, 10%, 14%\n",
        "   - Wastes material without benefit\n",
        "   - **Statistically confirmed inferior** to 8% and 10%\n",
        "\n",
        "3. **⚠️ DO NOT use linear interpolation**\n",
        "   - Relationship is non-monotonic\n",
        "   - Linear formula would give wrong predictions\n",
        "   - Use categorical means from ANOVA instead\n",
        "\n",
        "---\n",
        "\n",
        "## 7️⃣ Statistical Summary\n",
        "\n",
        "### Why ANOVA works but Linear Regression fails:\n",
        "\n",
        "| Approach | Assumption | Result |\n",
        "|----------|-----------|--------|\n",
        "| **ANOVA** | Concentrations are categorical (no order) | ✅ p=0.0021 (significant) |\n",
        "| **Linear Regression** | Linear relationship with concentration | ❌ Cannot fit non-monotonic data |\n",
        "\n",
        "**Lesson:** Always check for non-linear patterns before using linear regression!\n",
        "\n",
        "### Model Diagnostics:\n",
        "\n",
        "✅ **Normality:** Q-Q plot shows acceptable normality  \n",
        "✅ **Model fit:** R² = 0.9352 (excellent fit)  \n",
        "⚠️ **Outliers:** Some potential outliers detected\n",
        "\n",
        "---\n",
        "\n",
        "## 8️⃣ Summary Table\n",
        "\n",
        "| Question | Answer |\n",
        "|----------|--------|\n",
        "| **Do concentrations differ?** | ✅ Yes (ANOVA p=0.0021) |\n",
        "| **Optimal concentration?** | ⭐ **10%** (strength=146.00) |\n",
        "| **Worst concentration?** | 2% (strength=117.00) |\n",
        "| **Is relationship linear?** | ❌ NO (non-monotonic, peak at 10%) |\n",
        "| **Linear regression valid?** | ❌ NO (cannot capture drop at 12%) |\n",
        "| **Days significant?** | ❌ No (p=0.0701) |\n",
        "| **Main finding robust?** | ✅ YES (confirmed by Tukey test) |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔟 Additional Note on Variance Stabilization\n",
        "\n",
        "The analysis also tested **6 different approaches** to address heteroscedasticity:\n",
        "\n",
        "1. Original data\n",
        "2. Box-Cox transformation\n",
        "3. Log transformation\n",
        "4. Square root transformation  \n",
        "5. Weighted Least Squares (by Concentration)\n",
        "6. Weighted Least Squares (by Fitted Values)\n",
        "\n",
        "**Result:** The concentration effect remains **highly significant (p < 0.05) across ALL methods**, demonstrating the **robustness** of our main finding.\n",
        "\n",
        "**Recommendation:** Use the approach with lowest variance ratio - WLS (by fitted values) for final inference, but main conclusions are valid regardless of method chosen."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}